% -*- root: These.tex -*-

\Anotecontent{holland_multi_utilisation}{ Holland a développé les GA avant tout pour leur capacité de \foreignquote{english}{robust adaptive systems} et pas seulement pour leur capacité d'optimisation comme le rapelle \textcite{DeJong1993a} : \foreignquote{english}{However, with all this activity, there is a tendency to equate GAs with function optimization. There is a subtle but important difference between \enquote{GAs \textbf{as} function optimizers} and \enquote{GAs \textbf{are} function optimizers}} ; L'investissement d'Holland dans l'étude des \foreignquote{english}{Complex Adaptive Systems} s'inscrit dans une trajectoire de recherche resté proche des thématiques de ce qui deviendra plus tard la méta-discipline \textit{Artificial Life}. Son investissement continue dans cette branche de développement est d'ailleur lisible au travers de deux plateformes successive sur ce thème : \textit{$\alpha$-universe} et \textit{Echo} dont on trouve une analyse dans les travaux de \autocites{Taylor1999, Taylor2001} }


\Anotecontent{difference_objective_heuristique}{Il n'est pas forcément évident de faire la différence entre ces termes très proche, dont le sens se recoupe parfois, voici donc une aide à la désambiguisation inspirée de celle de \textcite[36]{Weise2011} :

\begin{enumerate}[labelindent=\parindent,leftmargin=*]
\item La fonction objectif (\textit{objective function}) peut etre considérée comme une forme d'heuristique, à la différence que celle ci est une mesure forcément directe du potentiel d'un aspect de la solution, alors que l'heuristique peut être de mesure directe ou indirecte, en ne fournissant par exemple qu'une approximation de la distance séparant une mesure de l'optimum. En ce sens, la fonction objectif mobilise souvent plus d'expertise sur le système que l'heuristique.
\item Une fonction \textit{fitness} est une fonction d'utilité secondaire, conçu comme une combinaison possible de fonction objectifs, et/ou d'heuristiques. Celle-ci peut également être une mesure relative, pour quantifier par exemple la différence existante entre deux solutions.
\end{enumerate}}

\Anotecontent{barricelli_multi_utilisation}{ Tout comme les travaux de McMillan ont permis de voir plus clair dans les intentions de Von Neumman derrière la notion de \textit{self-reproduction automata} ..., les travaux de Dyson \Autocite{Dyson1997}, de Fogel \autocite{Fogel2006a} sur l'histoire de cette discipline a permis également de redécouvrir les recherches de Barricelli comme celle d'un véritable pionnier en ALife, mais également comme celui d'un pionnier dans l'idée d'utiliser l'évolution comme support à la résolution de problème.}

\Anotecontent{fraser_comment}{\foreignquote{english}{Fraser was one of the first to conceive and execute computersimulations of genetic systems, and his efforts in the 1950s and1960s had a profound impact on computational models of evo-lutionary systems. The simulation algorithms he used were im-portant not only in the simulation of genetical problems, but pro-vided a menu of techniques that enriched the entire simulationeffort in any problem that involved probability sampling amonga population of alternatives, the heart of Monte Carlo methods. }\autocite[429]{Fogel2002}}

\Anotecontent{note_pattee_semantic_closure}{ \foreignquote{english}{Additionnary, from an epistemological point of view, Pattee(1995b) points out taht symbolic information (such as that contained in an organisms's genes) has \enquote{no instrinsic meaning outside the context of an entire symbol system as well as the material organization that constructs(writes) and interprets(reads) the symbol for a specific function, such a classification, control, construction, communication ...}. He argues that a necessary condition for an organism to be capable of creative open-ended evolution is that it encapsulates this entire self-referent organisation (Pattee refers to this condition as semantic closure). From this it follows that organisms should be constructed \enquote{with the parts and the laws of an artifical physical world} Pattee (1995a)(p.36). In other words, the interpretation (phenotype) of the symbolic information (genotype) of an artificial organism should be constructed and act within the artificial physical environment of the system. Additionally, if the system is to model the \enquote{origin} of genetic information, then the genotype itself must also be embedded within the environment; that is, the complete semantically-closed organisation -- the \enquote{entire organism} -- must be completely embedded within the physical environment.} \autocite{Taylor2001}} 

\Anotecontent{np_complet_def}{ \foreignquote{english}{Identifying which combinatorial problems are easy to solve and which are hard is an important and challenging task, which has occupied theoretical computer scientists for many years. In order to translate the everyday expression \enquote{easy to solve} to mathematical theory the concept of polynomial time algorithms has been introduced. An algorithm is said to run in polynomial time if there is a polynomial $p$ such that the algorithm applied to an input of size $n$ always finds a solution in time $p(n)$, that is after performing $p(n)$ simple instructions. Note that we measure the worst case complexity, that is the time in which we are sure that the algorithm ends regardless of which input of size $n$ we have fed it. The execution time of a polynomial time algorithm grows slowly enough with increasing input size to be able to be run on a computer, but if the execution time grows exponentially the algorithm is useless for all but the smallest inputs. One of the most accepted ways to prove that a problem is hard is to prove it NP-complete. If an optimization problem is NP-complete we are almost certain that it cannot be solved optimally in polynomial time.} \autocite[1]{Kann1992}}

\Anotecontent{billet_weise}{Voir le \href{http://blog.it-weise.de/p/309}{@billet} daté de juin 2014.}

\Anotecontent{note_pengouin}{Que faut il penser par exemple d'un algorithme bio lorsqu'il est nommé \foreignquote{english}{Pengouin Search Optimization Algorithm} (PSOea) \autocite{Gheraibia2013} ? }

\Anotecontent{stochastic_note}{Si l'optimisation stochastique (\textit{stochastic optimization}) ou approche probabiliste de l'optimisation (\textit{probabilistic approaches} apparait comme un autre chapeau susceptible de pouvoir englober l'ensemble de ces techniques, le schéma \ref{fig:S_OverviewOptimisation} de Weise contredit ce constat. Il existe en effet dans cette vaste catégorie tout un ensemble de techniques (\textit{Hill Climbing}, \textit{Simulated Annealing}, etc.) qui diffèrent très fortement dans leur structure, leur définition, ou leur inspiration, de la branche de techniques qui nous préoccupe ici, à savoir l'EC. }

\Anotecontent{equipe_mixite}{Suivant les travaux menés dans notre équipe par \textcite{Reuillon2014}, la validité de ce dernier paragraphe est clairement remise en question. L'originalité de ces derniers résident dans la mixité de ces deux objectifs. En intégrant \enquote{la capacité d'extension spatiale} dans l'exploration de ces espaces comme un critère d'optimisation supplémentaire aux objectifs plus classique de recherche de minima, une cartographie dirigée et plus exhaustive est devenue possible.}
%En intégrant l'\enquote{exploration de cette espace} des solutions (si on veut découvrir une carte  exhaustive des solutions optimisés), ou de l'espace de recherche (si on veut cartographier l'espace de recherche menant à cet espace de solution optimisé) comme un objectif d'optimisation supplémentaire aux objectifs plus classique de recherche de minima, une cartographie dirigé et plus exhaustive de certaines zones de cet espace est devenu possible.}


\Anotecontent{def_meta_sorensen}{\foreignquote{english}{A metaheuristic is a high-level problem-independent algorithmic framework that provides a set of guidelines or strategies to develop heuristic optimization algorithms (Sörensen and Glover, 2013). [...] A problem-specific implementation of a heuristic optimization algorithm according to the guidelines expressed in a metaheuristic framework is also referred to as a metaheuristic. The term was coined by Glover (1986) and combines the Greek prefix meta- (metá, beyond in the sense of high-level) with heuristic (from the Greek heuriskein or euriskein, to search)} \autocite{Sorensen2013} } 

\Anotecontent{def_meta_weise}{C'est également ainsi que \textcite[36, 225]{Weise2011} comprend ce terme \foreignquote{english}{A metaheuristic is a method for solving general classes of problems. It combines utility measures such as objective functions or heuristics in an abstract and hopefully efficient way, usually without utilizing deeper insight into their structure, i. e., by treating them as black box-procedures}}

\Anotecontent{greedy_description}{Un \enquote{choix optimal local} est réalisé à chaque itération durant l'optimisation, ce qui produit en général des solutions viables mais très rarement optimales.}

\Anotecontent{q_ppr}{Questions tirés du wiki \textit{Portland Pattern Repository} (\href{http://c2.com/cgi/wiki?MetaHeuristic}{@PPR}), qui est au passage un des premier wiki sur le web (1995)}

\Anotecontent{paysage_cumule}{En ce sens, la figure \ref{fig:spacePspaceOmultimodal} peut représenter tout autant \begin{enumerate*}[label=(\alph*)]
\item un ensemble de population de solutions candidates désignées en amont par un plan d'expérience, évaluées en une seule passe par l'optimiseur, puis projetté dans l'espace des objectifs
\item ou, un cumul de population candidates évaluées représentatif du fonctionnement de l'optimiseur étalé sur plusieurs passes, celui-ci manipulant entre chaque itération non pas une population, mais un seul individu solution candidate. \end{enumerate*} }

\Anotecontent{test_fonction_surutilisation}{Sous l'impulsion remarquée de quelques chercheurs \autocite{Zitzler1999a, Zitzler1999b, Fonseca1996}, différentes approches ont étés formalisés ces dernières années pour mieux mesurer et comparer les performances de ces différents algorithmes d'optimisation. Ces approches et ces mesures sont régulièrement comparées, et utilisées de façon complémentaire dans la littérature informatique pour confronter au mieux les nouveaux algorithmes dont on rapelle qu'ils sont stochastique, et donc plus difficile à évaluer les uns rapport aux autres \autocite{Coello2006}. Cette évolution passe par la création d'un certain nombre de \textit{benchmark}, avec par exemple l'évaluation par les algorithmes de set de fonctions mathématiques (comme ceux de Schwefel et DeJong)dont on connait la forme du front de Pareto \autocites[580]{Weise2011}[138]{Back1996}, en utilisant diverses mesures (sur le paysage \autocite[163]{Weise2011}, sur les opérateurs de comparaisons utilisés pour différencier les algorithmes \autocite{Zitzler2003, Zitzler2007}, etc.) et leur mise en oeuvre automatisée par le biais de plateformes dédiées, comme la plateforme COCO (COmparing Continuous Optimisers) \autocite{Hansen2011} utilisée depuis 2009 pour les conférences prestigieuses de GECCO. Nécessaire dans l'établissement théorique de la discipline, un point de vue réflexif et critique des chercheurs dans cette discipline ont pour effet d'engager de nouvelles réflexions, et paradoxalement, parce qu'il faut bien trouver un moyen de comparer ces algorithmes, invente de nouvelle fonctions tests et de nouvelle mesures : \foreignquote{english}{Zitzler et al. 2000 stated that, when assessing performance of an MOEA, one was interested in measuring three things: 1. Maximize the number of elements of the Pareto optimal set found. 2. Minimize the distance of the Pareto front produced by our algorithm with respect to the global Pareto front (assuming we know its location). 3. Maximize the spread of solutions found, so that we can have a distribution of vectors as smooth and uniform as possible. This, however, raised some issues. First, it was required to know beforehand the exact location of the true Pareto front of a problem in order to use a performance measure. This may not be possible in real-world problems in which the location of the true Pareto front is unknown. The second issue was that it is unlikely that a single performance measure can assess the three things indicated by Zitzler et al. 2000.} \autocite{Coello2006} Différents auteurs, dont certains pionniers créateurs de ces même fonctions, se sont récemment adressés à la communauté sur ce sujet, en demandant si possible d'arreter d'utiliser ces fonctions types. \hl{ref à rajouter}}

\Anotecontent{remarque_section_metaheuristique}{Ce constat n'est pas forcément évident avec les exemples utilisés jusqu'à présent, mais il faut imaginer que l'optimiseur va jouer avec les valeurs $x$ et $y$ en fonction de leur espace respectif et des contraintes possiblement associés, et \textbf{non pas en se déplacant physiquement} sur le plan 2D $(x,y)$, que l'on a utilisé ici avant tout pour des facilité de représentation. Les qualités topologiques de cet espace (dans quel cluster de solution candidates je me situe ? ou se situe les prochains clusters voisins intéressant à explorer ? les clusters de valeur $v$ sont il très homogènes, très hétérogènes etc.) qui pourraient effectivement permettre de dégager des informations utiles dans la selection des futures solutions candidates ne sont généralement pas pris en compte de façon initiale par la plupart des métaheuristiques que nous allons étudier, à moins qu'on ne leur en donne les moyens. L'expertise de l'espace des solutions candidates évalués, ou espace des objectifs, est bien plus souvent mobilisé pour motiver les nouvelles solutions candidates à évaluer, comme on va pouvoir le découvrir dans la section suivante. Il existe donc de nombreuses possibilités pour intégrer diverses connaissances améliorant les choix de l'optimiseur, la prospection intelligente des différents espace à sa disposition en fait partie.}

\Anotecontent{note_knapsack}{Dans le problème du sac-à-doc, ou \textit{Knapsack problem}, il s'agit de trouver la combinaisons idéale d'objets disposant d'une masse et d'une valeur, en essayant de maximiser la somme calculée à partir de la valeur des objets que l'on arrive à entrer dans le conteneur. C'est un problème d'optimisation discret NP-Complet, difficile à résoudre lorsque le nombre d'éléments pris en compte augmente, au même titre que le voyageur de commerce.}

\Anotecontent{notation_dominance}{On trouve également cette notation sous la forme inverse dans la littérature. C'est par exemple le cas dans les écrits de \textcites{Deb2000a,Deb2002}, créateur de l'algorithme multi-objectifs très utilisé et très connu nommé NSGA2. La relation de domination entre deux éléments est écrite en utilisant le symbole inverse $x_1 \prec x_2$, signifiant $x_1$ domine $x_2$. Une des explications possible est la suivante : \foreignquote{english}{$x^* \succ x$ to indicate that $x^*$ dominates $x$.This notation can be confusing because the symbol $\succ$ looks like a \enquote{greater than} symbol but since we deal mainly with minimization problems, the symbol \enquote{$\succ$} means the function values of $x^*$ are less than or equal to those of $x$. However this notation is standard in the literature, so this is the notation that we use.} Le signe serait donc couramment retourné pour éviter une possible confusion. \hl{ref à ajouter : A Tutorial on the Performance Assessment of Stochastic Multiobjective Optimizers et Zitzler2003 ... A voir dans goldberg1989 puisque c'est lui le premier qui l'a utilisé si on en croit certain papier} }

\Anotecontent{def_convergence}{\foreignquote{english}{An optimization algorithm has converged (a) if it cannot reach new candidate solutions anymore or (b) if it keeps on producing candidate solutions from a “small” subset of the problem space.} \autocite[251]{Weise2011}}

\Anotecontent{remarque_resolution}{Une remarque qui ouvre la possibilité d'autres questionnements, comme celui par exemple de la résolution et de la sensibilité à partir desquels on identifie deux solutions comme différentes, alors même que les algorithmes sont entrainés à faire la différence entre deux évaluations en tenant compte d'écarts infimes ? Cette remarque est également valable pour l'échantillonage des valeurs de $x$, si l'optimiseur est contraint de selectionner les valeurs selon un seuil de résolution fixé par un seuil (un pas de 0.1 par exemple), ne prend-t-on pas le risque important de passer à coté d'optimum plus intéressants ?}

\Anotecontent{note_weak}{\foreignquote{english}{[...] In fitness landscapes with weak (low) causality, small changes in the candidate solutions often lead to large changes in the objective values, i. e., ruggedness. It then becomes harder to decide which region of the problem space to explore and the optimizer cannot find reliable gradient information to follow. A small modification of a very bad candidate solution may then lead to a new local optimum and the best candidate solution currently known may be surrounded by points that are inferior to all other tested individuals. The lower the causality of an optimization problem, the more rugged its fitness landscape is, which leads to a degeneration of the performance of the optimizer [1563].} \autocite[162]{Weise2011}}

\Anotecontent{note_strong}{\foreignquote{english}{During an optimization process, new points in the search space are created by the search operations. Generally we can assume that the genotypes which are the input of the search operations correspond to phenotypes which have previously been selected. Usually, the better or the more promising an individual is, the higher are its chances of being selected for further investigation. Reversing this statement suggests that individuals which are passed to the search operations are likely to have a good fitness. Since the fitness of a candidate solution depends on its properties, it can be assumed that the features of these individuals are not so bad either. It should thus be possible for the optimizer to introduce slight changes to their properties in order to find out whether they can be improved any further. Normally, such exploitive modifications should also lead to small changes in the objective values and hence, in the fitness of the candidate solution.} \\ La définition donné par Weise pour une \textit{strong causality} est donc la suivante \foreignquote{english}{Strong causality (locality) means that small changes in the properties of an object also lead to small changes in its behavior.} \autocite[161]{Weise2011}}

\Anotecontent{note_elitisme}{Les stratégie d'élitisme visent à s'assurer que les meilleures solutions ne seront jamais perdues, et cela quelque soit le déroulement de l'algorithme : \foreignquote{english}{No matter how elitism is introduced, it makes sure that the fitness of the population-best solution does not deteriorate. In this way, a good solution found early on in the run will never be lost unless a better solution is discovered. The absence of elitism does not guarantee this aspect.} Une propriété qui n'est pas garantie dans les premières générations d'algorithmes EA d'optimisation multi-objectifs. On trouvera plus de détail sur ce terme dans les pages d'ou cette précédente définition a été tiré \autocite[239-240]{Deb2001}. L'introduction de ce concept, bien que daté de \hl{(ref De Jong, 1975)}, est attribué à Zitzler dans sa version multi-objectif si on en croit \textcite{Coello2006}, qui en donne la définition suivante \foreignquote{english}{In the context of multi-objective optimization, elitism usually (although not necessarily) refers to the use of an external population (also called secondary population) to retain the nondominated individuals found along the evolutionary process. The main motivation for this mechanism is the fact that a solution that is nondominated with respect to its current population is not necessarily nondominated with respect to all the populations that are produced by an evolutionary algorithm. Thus, what we need is a way of guaranteeing that the solutions that we will report to the user are nondominated with respect to every other solution that our algorithm has produced. Therefore, the most intuitive way of doing this is by storing in an external memory (or archive) all the nondominated solutions found. If a solution that wishes to enter the archive is dominated by its contents, then it is not allowed to enter.}}

\Anotecontent{martin_fowler}{L'auteur informaticien Martin Fowler, qui s'est intéressé dans plusieurs articles à l'étymologie de ce principe d'inversion de contrôle, et à sa relation proche avec l'injection de dépendance, fournit un élément de réponse sur la différence entre le concept de librairie logicielle et celui de \textit{framework} : \foreignquote{english}{Inversion of Control is a key part of what makes a framework different to a library. A library is essentially a set of functions that you can call, these days usually organized into classes. Each call does some work and returns control to the client. A framework embodies some abstract design, with more behavior built in. In order to use it you need to insert your behavior into various places in the framework either by subclassing or by plugging in your own classes. The framework's code then calls your code at these points.} L'article complet est accessible sur le \href{http://martinfowler.com/bliki/InversionOfControl.html}{@site} de l'auteur.}

\Anotecontent{sean_luke_mason}{\foreignquote{english}{In 1998, after using a variety of genetic programming and evolutionary computation toolkits for my thesis work, I decided to develop ECJ, a big evolutionary computation toolkit which was meant to support my own research for the next ten years or so. ECJ turned out pretty well: it’s used verywidely in the evolutionary computation field and can run on a lot of machines in parallel. [...] One common task (for me anyway) for evolutionary computation is the optimization of agent behaviorsin large multiagent simulations. ECJ can distribute many such simulations in parallel across simultaneousmachines. But the number of simulations that must be run (often around 100,000) makes it fairly important to run them very efficiently. For this reason I and my students cooked up a plan to develop a multiagentsimulation toolkit which could be used for various purposes, but which was fast and had a small and cleanmodel, and so could easily be tied to ECJ to optimize, for example, swarm robotics behaviors.} \autocite[8]{Luke2014}}

\Anotecontent{sean_luke_ecj}{\foreignquote{english}{ECJ is an evolutionary computation framework written in Java. The system was designed for large, heavy- weight experimental needs and provides tools which provide many popular EC algorithms and conventions of EC algorithms, but with a particular emphasis towards genetic programming. ECJ is free open-source with a BSD-style academic license (AFL 3.0). ECJ is now well over ten years old and is a mature, stable framework which has (fortunately) exhibited relatively few serious bugs over the years. Its design has readily accommodated many later additions, including multiobjective optimization algorithms, island models, master/slave evaluation facilities, coevolution, steady-state and evolution strategies methods, parsimony pressure techniques, and various new individual representations (for example, rule-sets). The system is widely used in the genetic programming community and is reasonably popular in the EC community at large. I myself have used it in over thirty or forty publications.} \autocite[7]{Luke2014b}}

\Anotecontent{sean_luke_masondifficile}{\foreignquote{english}{MASON is not an easy toolkit for Java beginners. MASON expects significant Java knowledge out of its users. If you are a rank beginner, allow me to recommend NetLogo, a good toolkit with an easy-to-learn language. [...] Finally MASON does not have plug-in facilities for Eclipse or NetBeans, though it can be used quite comfortably with them. If you’re looking for a richer set of development tools, you might look into Repast. }\autocite[8]{Luke2014}}

\Anotecontent{sean_luke_ecjdifficile}{\foreignquote{english}{A toolkit such as this is not for everyone. ECJ was designed for big projects and to provide many facilities, and this comes with a relatively steep learning curve.} \autocite[7]{Luke2014b}}

\Anotecontent{coello_note}{Le chercheur \textcite{Coello2015} est un auteur régulier d'états de l'art \autocite{Coello1999, Coello2000, Coello2007} ou d'articles \autocite{Coello2006} sur l'historique de cette branche spécifique de l'EC concentré sur la résolution de problèmes multi-objectifs maintient également sur son \href{http://www.lania.mx/∼ccoello/EMOO/}{@site} une base de données bibliographiques riche à ce jour de plus de 9000 entrées.}

\Anotecontent{reflexion_DeJong}{\foreignquote{english}{By understanding the role each element plays in the overall behavior and performance of an EA, it is possible tomake informed choices about how the elements should be instantiated for a particular application. At the same time, it is clear that these components interact with each other so as to affect the behavior of simple EAs in complex, nonlinear ways. This means that no one particular choice for a basic element is likely to be universally optimal. Rather, an effective EA is one with a co-adapted set of components.}\autocite[70]{DeJong2006a}}

