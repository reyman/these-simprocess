
\subsection{De la validation à la construction des modèles de simulation par l'évaluation}
\label{ssec:evaluation_construction}

% Permanence des questions évoqués pour la construction d'un modèle de simulation, plus complexification de la validation liés à la pluriformalisation.

En montrant que la validation est dépendante au contexte, Hermann a permis de lever un certain nombre de questions remarquables par leur actualité dans le cadre de nos propre problématique de construction.  %La mise en avant d'une possibilité de validation dépendante à l'objectif nous oblige inévitablement à prendre en compte l'activité de construction comme activité validante.

\subsubsection{Des modalités de validation dépendante au contexte, l'apport d'Hermann à une première formalisation du problème}

\paragraph{Une vision de la validation différente chez les pionniers du mouvement S\&G}

Charles F. Hermann opère dans la branche des simulations appelées à l'époque par Shubik les \textit{Man-Machine Games} \autocite{Shubik1972}. Une catégorie de simulation qui intègre dans son exécution un couplage entre un ou plusieurs systèmes numériques et des humains, qui peuvent être amenés à interagir entre eux, ou avec les machines. Ce type de simulation de structure hétérogène est intéressante dans le sens où elle permet d'intégrer l'arbitraire humain dans une chaîne d'interaction complexe qui n'aurait pas pu être établie autrement, du fait de l'impossibilité de programmer des interactions et des réactions humaines face à des situations précises. Même si ce type de techniques est motivé par une multitude d'usages, ce n'est pas par hasard si elle se développe particulièrement au cours de la guerre froide aux Etats-unis, toujours sous la direction d'institutions militaires. Ce genre de techniques permettant par exemple de simuler et de reproduire des guerres au travers d'inter-relations diplomatiques et/ou économiques \autocite{Hermann1967b}, avec la possibilité de mesurer via des indicateurs adaptés l'importance et l'impact de différents scénarii sur le couple humain/machine.

Ce type de simulation est particulièrement représenté dans des publications qui traitent de la simulation au sens large, comme par exemple le journal \textit{Simulation and Gaming} ou \textit{S\&G} \autocite{Crookall2011}, dont l'activité remonte au début des années 1970. On retrouve parmi les auteurs ayant participé au développement de la discipline des personnalités importantes comme Guetzkow, Shubik, Coleman, etc. \autocite{Crookall2012}. Aujourd'hui, le terme à évolué vers ce que l'on pourrait probablement appeler des jeux sérieux, l'utilisation de l'ordinateur n'étant plus forcément un élément obligatoire dans ce type de simulation. Du côté des objectifs qui sont aujourd'hui susceptibles de motiver l'utilisation de ces techniques, \textcite{Shubik2009} définit une taxonomie en 6 objectifs : \textit{teaching, experimentation, entertainment, therapy and diagnosis, operations, training }

Cette présence d'une dimension humaine dans les simulations introduit une complexité qui touche forcément à plusieurs objets d'études des sciences humaines (psychologie, sociologie, etc.), et il n'est donc pas étonnant que l'on retrouve ce type de publication dès l'apparition des premiers ouvrages inter-disciplinaires sur la simulation, quand elle ne les pilote pas; Harold Guetzkow par exemple est un des personnages importants qui gravitent autour de Herbert Simon au GSIA (Graduate School of Industrial Administration) de Carnegie Tech dans les années 1950-56 \autocite{Guetzkow2004}, et qui a beaucoup oeuvré pour le développement de la simulation dans ces sciences politiques et psychologiques (\textit{Inter-Nation simulation laboratory}) \autocite{Janda2011, Druckman2010}. Celui ci s'inscrit exactement dans la même branche que Hermann, et apparaît deux fois comme premier éditeur dans des recueils de textes pluri-disciplinaires traitant de la simulation au sens large, preuve aussi de son implication dans le développement et la diffusion de ces techniques au delà de sa propre discipline \autocite{Guetzkow1962, Guetzkow1972}

\paragraph{L'apport du contexte dans l'évolution du sens attaché à l'activité de simulation}

Ce qui est intéressant dans ce type de simulations, c'est qu'elles forcent à penser la validation des modèles sous un angle qui doit nécessairement tenir compte de la variabilité inhérente aux comportements humains, par essence difficilement évaluables et réplicables. C'est de cette contrainte, et parce que \textcite{Hermann1967} s'intéresse aux modèles de simulation pour d'autres objectifs que la prédiction (\textit{teaching, training, theory-building}), que celui-ci développe à mon sens une vision de la validation beaucoup plus réaliste pour les sciences sociales que celle proposée à la même période par Naylor.

\foreignquote{english}{First, the validity of an operating system is affected by the purpose or use for which the game or simulation is constructed [...]}\autocite[217]{Hermann1967}

% Plus d'information à ajouter, soit sur la dite boucle (sachant que le conceptual correspond quand meme pas mal à ce que lon fait, voir Sargent2010), Si la boucle définit par les tenants de la \textit{V\&V} n'est pas inintéressante, et de façon générale résume bien le cycle de vie qui correspond à la construction d'une simulation, de nombreuses questions reste en suspens sur le choix et la mise en œuvre des techniques telles qu'elles sont décrites. La construction et la mise en oeuvre des critères en fait partie. Les objectifs sont cités dans la définitions mais on ne rentre pourtant pas dans le détail de la relation entre ces objectifs et la construction du modèle, qui est laissé à l'expertise de l'utilisateur, en cela Hermann ne propose pas mieux dans sa description d'une boucle modélisatrice que les dernières avancées portés par Sargent2010, toutefois sa réflexion est par son orientation, et par sa précocité de réflexion son intéressante il me semble à citer. les moyens technique de la mise en oeuvre par exemple ? 

%Dans l'explication sociologique, la réalité structurelle n'est pas forcément d'intérét pour la construction du modèle. (bulle)

%Cette observation amène Hermann à considérer que la validation des composantes de la structure mérite une attention tout aussi importante que la seule comparaison avec des données de sorties, notamment dans un cadre explicatif.  curl -k -o ~/backups/pinboard-backups/pinboard-$(date +\%y\%m\%d).json 'https://api.pinboard.in/v1/posts/all?&auth_token=username:APItokenhere&format=json'

En s'appuyant sur ce premier argument évoquant l'existence d'une dépendance liant processus de validation et objectif poursuivi par le modélisateur, Hermann semble \textit{de facto} mettre en défaut une définition de la simulation ayant comme première et unique vocation de représenter au mieux le système observé. Les modalités de la validation étant maintenant définies par rapport au contexte, la possibilité d'un critère unique pour juger de la validation de façon universelle paraît tout à fait improbable. Afin de montrer qu'il ne s'agit pas seulement d'une question de disponibilités des données, et pour amener par la suite sa proposition de méthode multi-critères, Hermann s'attaque donc en premier lieu à réduire la portée des confirmations apportées sur un système observé par l'emploi de la seule technique de validation basée sur la comparaison de données en sortie des modèles de simulation.

Pour montrer qu'il existe des limitations dans la confiance que l'on peut mettre dans la validation lorsqu'il s'agit de comparer des données historiques (dans le cas des simulations de reproduction de guerre, on parle ici plutôt de reproduire des séries d'événements historiques) -cela même si elles sont idéalement toute rendues disponible- aux données en sorties de simulation, \textcite{Hermann1967b} s'appuient sur les travaux de \textcite{Pool1965}.

\foreignblockquote{english}[\cite{Pool1965}]{This correspondence does not demonstrate that the simulation correctly represents the structure and processes that were operative in the historical occurence. We are speculating on the similarity between the historical and simulated inputs on the basis of the similarity of their outputs. Different relationships among various combination of properties in the simulation conceivably could produce outcomes like those in the historical situation.

A simulation of the 1960 national Presidential election predicted the percentage of the vote for each candidate - the outcome - with considerable success. The designers of that simulation observe, however, that \enquote{it may legitimaly be asked what in the equations accounted for this success, and whether there were parts of the equations in the simulation that contributed nothing or even did harm} Further analysis of the equations in the simulation revealed that the outcome was predicted despite the fact that at least one equation misrepresented aspects of voter turnout. Part of the structure was incorrect, but the simulated result still matched the actual outcome. Despite this difficulty, our confidence that the simulation has captured some aspects of the voting process is greater than it would have been if the simulation had failed to replicate the campaign outcome. Confidence in the simulation would increase further as the operating model demonstrated ability to produce outcomes that corresponded with various elections. In sum, the similarity between simulation and historical events can provide at best only indirect and partial evidence for the correctness of the simulated structures and processes that produced the outcome.}

Ce que nous dit Hermann ici, à la différence de Naylor, c'est que même dans le cas idéal ou toutes les données serait présente, ce mode classique de validation ne peut pas être suffisant, cela quelque soit l'objectif poursuivi par le modélisateur. Un constat que nous avions déjà acquis à la lecture des déboires des géographes avec les préceptes de validation néo-positivistes, associant dans une démarche de modélisation instrumentaliste prédiction et explication (section \ref{sssec:realite_neopositiviste}).

Ce constat reste encore valide aujourd'hui, car comme le rappelle très justement \textcite[32]{Bulle2005}, \enquote{ les problèmes posés en sciences humaines visent cependant, en général, la compréhension des phénomènes. Dans cette optique, l’objet premier de la modélisation n’est pas de faire \enquote{coïncider} les modèles construits avec la réalité qui est celle des effets. Le test par la prévision ne peut assurer des qualités explicatives des modèles.}

Un point de vue partagé par \textcite[106]{Amblard2006}, pour qui \enquote{[...] la recherche de similitudes avec les données, si elle peut être utile, ne peut absolument pas être un critère unique et définitif de validation}

Suivant ces conseil, si Forrester avait appliqué lors de la construction de son modèle \textit{Urban Dynamics} des analyses de sensibilités (voir le type de critère \textit{variable-parameter testing} de \autocite{Hermann1967}) tel que le propose Hermann, il aurait probablement conclu, comme ont pu faire ces détracteurs par la suite, à l'inutilité d'une bonne partie des hypothèses intégrés dans son modèle, qui s'avèrent en réalité très peu influente sur la dynamique observé en sortie des simulations.

Autre point important, l'existence de multiples objectifs de modélisation permet à Hermann certe de révéler la diversité et l'attachement de la validation à un contexte, mais surtout de noter d'une part comment la variation de ce dernier affecte les modalités de cette comparaison entre système simulé et système observé, et d'autre part comment cela affecte la perception du résultat engendré par cette comparaison.

\foreignblockquote{english}[{\cite[219]{Hermann1967}}]{The first comment is that the validation of an operating model cannot be separated from the purpose for which it is designed and used. [...] The second observation somewhat mediates the first. For the most part the various purposes for conducting games and simulations do not negate the need for criteria we can use to estimate the degree of fidelity with which one system (the operating model) reproduces aspects of another (the reference system). Given some purposes for using games and simulations (such as exploring nonexistent universes), finding appropriate criteria in the referent system is quite difficult. With other objectives, the value of the operating model may remain even if the fit between the model and various criteria representing the observable universe is poor (as in theory building).} 

Indirectement, on observe ici le transfert d'une définition de la simulation comme simple \enquote{type de modèle} vers la définition plus générale d'une simulation \enquote{ caractérisée non pas tant par l’unité d’une fonction cognitive qu’elle assurerait toujours sous une forme ou sous une autre que par son fonctionnement interne, fonctionnement qui, bien sûr, mais seulement secondairement, se trouve avoir aussi des conséquences sur sa ou ses fonctions cognitives. Une simulation nous paraît ainsi devoir être prioritairement caractérisée par ce qu’elle est – ou fait – de manière interne plutôt que par ce qu’elle fait au sens d’une fonction cognitive quelconque qu’elle assurerait toujours et qu’on en attendrait prioritairement de l’extérieur : à ce titre, nous proposons de dire qu’\textit{elle est avant tout un traitement spécifique sur des symboles et qui prend toujours la forme d'au moins deux phases distinctes. 1) une phase opératoire [...] 2) une phase d'observation [...]}} \autocite[33-34]{Varenne2013}

\paragraph{La nécessité de repenser la représentativité des modèles}
\label{p:repenser la representativite}

La V\&V a toujours mis en avant le fait que la modélisation soit un processus incrémental tout à fait nécessaire pour obtenir un modèle de simulation satisfaisant, que cela soit dans les analyses de Naylor, ou d'Hermann. Ce dernier se réfère dès 1967 au principe de parcimonie, une méthode qui implique une abstraction, une simplification du système à représenter, et qui pour lui met logiquement et automatiquement en péril la représentativité. \Anote{Herman_parcimonie} 

%Une parcimonie hérité du principe d'Ockham dont on sait qu'elle n'est en aucun cas un synonyme de simplicité dans sa mise en oeuvre, celle-ci nécessitant au contraire un effort intellectuel important pour déterminer quelles sont les hypothèses réellement représentatives du problèmes à analyser. %Sur le plan de complexité, Poincarré ou le prix nobel d'économie Herbert Simon à fait état plusieurs fois des capacités d'expression du complexe rendu possible par l'usage de la simulation, et cela même avec des modèles simples.\autocite{Banos2013a}

%Une description de la construction des modèles qui coincide avec ce qui a été dit auparavant sur l'importance de la nature de l'objectif poursuivie sur la perception de cette \enquote{représentativité}, et le fait que cette dernière ne fasse pas systématiquement la valeur du modèle - tant soit peu qu'on arrive à fixer une valeur - 

Dans ce que l'on comprend de l'analyse d'Hermann, la perte de représentativité attendue d'un modèle de simulation qui n'est plus strictement dirigé vers la prédiction est compensée par un gain relatif à l'objectif poursuivi qui change la nature de la validation attendue : détection d'alternatives à un comportement, mise en avant de processus simplifiés pour l'éducation, construction de théorie, etc.

Il est donc logique de voir Hermann proposer dans la suite de son analyse de repenser la notion de représentativité et la notion de validation au regard de l'objectif poursuivi par le modélisateur. Il en résulte la généralisation de cette activité de validation dont le résultat se dessine à présent sous le couvert d'un objectif et dans le jeu d'une confrontation entre deux représentations, deux construits prenant pour cible le système modélisé et le système observé. 

\foreignquote{english}{A simulation or game is the partial representation of some independent system. Usually we are interested in simulation as a means for increasing our understanding of the system it is intended to copy. Therefore, the representativeness of a simulation or game becomes extremely important in assessing its value. The process of determining how well one system replicates properties of some other system is called validation.[...] In the present analysis however, validation will be defined more broadly as any comparison between the representation of a system and specified criteria.} \autocite[216]{Hermann1967}

\subsubsection{Le problème de la validation ramené à une confrontation des représentations entre système modélisé et système observé}
\label{ssec:confrontation_sysmodelise_sysobserve}

%\hl{repetition ?}
%La question de la représentativité d'une simulation est un sujet délicat à traiter car sa valeur se dessine à l'intersection d'au moins deux activités, la construction d'un modèle opérationel et la construction d'une grille d'évaluation, deux activités dont on s'apercoit par la suite qu'elles sont en réalité étroitement liées. 

\paragraph{Quelles hypothèses pour quelle représentativité ?}
\label{p:hypothese_representativite}

Si cette \enquote{representativité} ne semble plus intervenir dans la valeur du modèle que sous une forme beaucoup plus partielle, quelle est la part de représentativité acceptable que l'on peut attendre pour qu'une hypothèse soit considérée comme explicative ? Autrement dit quelles sont les modalités qui guident l'introduction maitrisée d'une part d'empirie dans un modèle, par l'existence d'un seuil caractérisant le potentiel de représentativité à atteindre pour chaque hypothèse ? Pour l'ensemble du modèle ? 

L'acceptation d'un gradient de valeur pour juger de la validation rompt avec la méthode \enquote{binaire} proposée par Naylor, la validation d'un modèle passant à présent par l'acceptation subjective d'un seuil de représentativité relatif à l'objectif poursuivi. Avec pour conséquence notable qu'une \foreignquote{english}{[...] simulation or game relatively valid for one objective may be not be equally valid for another.}

Si la notion de seuil n'est pas explicitement abordée par Hermann, c'est pourtant sous cette acceptation que la \textit{V\&V} actuelle va reprendre ce concept. Avec la position suivante, celui de se fixer un seuil de représentativité général à atteindre \textit{a priori}.

\foreignquote{english}{\textbf{Principle 2: The outcome of simulation model VV\&T should not be considered as a binary variable where the model is absolutely correct or absolutely incorrect } [...] The outcome of model VV\&T should be considered as a degree of credibility on a scale from 0 to 100, where 0 represents absolutely incorrect and 100 represents absolutely correct. 

\textbf{Principle 3: A simulation model is built with respect to the study objectives and its credibility is judged with respect to those objectives } [...] The study objectives dictate how representative the model should be. Sometimes, 60\% representation accuracy may be sufficient; sometimes, 95\% accuracy may be required depending on the importance of the decisions that will be made based on the simulation results. Therefore, model credibility must be judged with respect to the study objectives.}\autocite[15-16]{Balci1998}

La position de \textcite[166]{Sargent2010}, tout en étant relativement similaire, propose une vision plus fine et plus réaliste ou le seuil de précision attendu est attaché aux variables de sorties. Un point important sur lequel nous reviendrons plus longuement dans la suite de cette partie. \hl{ref vers la bonne partie}

\foreignquote{english}{A model should be developed for a specific purpose (or application) and its validity determined with respect to that purpose.[...] A model is considered valid for a set of experimental conditions if the model’s accuracy is within its acceptable range, which is the amount of accuracy required for the model’s intended purpose. This usually requires that the model’s output variables of interest (i.e., the model variables used in answering the questions that the model is being developed to answer) be identified and that their required amount of accuracy be specified. The amount of accuracy required should be specified prior to starting the development of the model or very early in the model development process.}\autocite[166]{Sargent2010}

\begin{figure}[h]
\begin{sidecaption}[fortoc]{ On remarquera la forte présence des techniques présentés par Hermann dans la synthèse proposé par Balci en 1986 \autocite{Balci1986}}[fig:S_syntheseBalci]
  \centering
 \includegraphics[width=.9\linewidth]{subjective_balci.png}
  \end{sidecaption}
\end{figure}

Ces deux citations permettent de montrer au passage comment la vision de la validation défendue par Hermann a été intégrée dans une forme très approchante par des acteurs de la \textit{V\&V} comme Balci ou Sargent, dont on a vu précédemment les définitions dans la section \ref{ssec:def_generique_validation}. Ces deux derniers sont en réalité les acteurs majeurs d'une synthèse (voir la figure \ref{fig:S_syntheseBalci}) opérée dans les années 1980-1990 \autocite{Nance2002}, dont on peut dire qu'elle est marquée par un retour à une certaine forme de neutralité (voir par exemple le rejet des aspects philosophiques décrits décrits dans la section \ref{ssec:def_generique_ validation}  qui se double d'un jargon technique spécifique à l'établissement d'un processus qualité exploitable pour l'ingénierie) . Des adaptations qui permettent probablement de mieux accepter en son sein des typologies de techniques aussi différentes que celle de Naylor\Anote{naylor_etonnement} ou Hermann. Régulièrement révisées, \textcite{Balci1998} fait ainsi état dans sa dernière taxonomie d'un catalogue de 75 techniques différentes dans lequel peuvent piocher les modélisateurs en fonction de leurs besoins. 

On se rend bien compte que dans le cadre des sciences humaines et sociales la possibilité de fixer par avance ce type de seuil n'a pas de sens, surtout dans un cadre explicatif.

%\textit{Que faut il entendre ici par partiellement ? Quels sont les leviers permettant au géographe de compenser cette perte de représentativité par un gain en compréhension sur le système à étudier ? }

Pour mieux comprendre quel est l'enjeu de cette délimitation entre un modèle réaliste et un modèle abstrait il faut évoquer cette tension permanente qui nourrit les choix du modélisateurs dans la construction d'un modèle explicatif. Deux attracteurs possibles et apparemment opposés, avec d'une part la volonté de se rattacher à une forme de réalisme au travers de l'injection d'une part maitrisée de réalité tout au long du processus de construction \Anote{durand_observation}, et d'autre part une force qui nous pousse au contraire à se détacher de cette même empirie pour ne retenir que le matériel susceptible de servir l'objectif du modèle.

La sociologue et épistémologue \textcite{Bulle2005} a bien formalisé ce dilemme dans la nécessité pour tout modélisateur de positionner son modèle sur un gradient opposant le réalisme des causes des modèles explicatifs \Anote{bulle_modele_explicatif}, au réalisme des effets des modèles descriptifs. 

Pour mieux comprendre quelles connaissances peut-on attendre d'un tel positionnement sur ce gradient, le mieux est encore de commencer par évoquer un de ses extrêmes, en invoquant par exemple le modèle universellement connu de Schelling. De par sa portée d'application extrêmement générale et la nature très abstraite de ses paramètres celui-ci constitue en soi un extrême intéressant pour comprendre où se situe encore l'explication lorsque le détachement de la réalité est à ce point éloigné. Sur ce point, les analyses de \textcite{Bulle2005} et \textcite{Phan2008, Phan2010} se réfèrent principalement à l'essai de \textcite{Sugden2002} pour évoquer quels types de relations entre les deux mondes peut on attendre de ce type de modèle épuré. 

Les résultats qui dérivent de la mise en dynamique des règles dans le modèle de Schelling sont d'une telle universalité, d'une telle robustesse qu'il n'est plus question de confronter les résultats ainsi obtenus à la réalité. A cet égard le potentiel explicatif de ce type de modèle s'oppose selon \textcite{Bulle2005} à tout réalisme empirique. De ce point de vue, \enquote{le modèle n'est pas tant une abstraction de la réalité qu’une réalité parallèle [...] bien que le monde du modèle soit plus simple que le monde réel, celui-ci n'est pas une simplification de l'autre. Le modèle est réaliste dans le même sens qu'un roman peut être appelé réaliste [...] les personnages et les lieux sont imaginaires, mais l'auteur doit nous convaincre qu'ils sont crédibles } \autocites[131]{Sugden2002}[10]{Phan2008}

L'effet d'une telle recombinaison d'hypothèses revient à mettre en oeuvre un \enquote{monde crédible} où l'inférence inductive est mobilisée pour identifier des similitudes significatives entre les deux mondes. \autocites{Livet2006, Phan2008}. Tout le travail réside donc dans l'interprétation prudente qui peut être faite entre ces résultats d'un monde factice et d'une réalité.

Un processus commun utilisé dans toute oeuvre de fiction pour piquer la curiosité de l'observateur, la mise en exergue volontaire d'une tendance du monde réel dans un monde imaginaire permettant d'entamer une réflexion sur l'existence, la portée, la nature de cette même tendance dans le monde réel. Les villes ou les sociétés mis en avant dans des oeuvres de fiction cinéma ou dans la littérature ne sont jamais que des mondes plus ou moins crédibles (Gotham City, 1984, Matrix, la série Black Mirror, etc. car la liste est longue ...)  pour mettre en avant un discours, ou des tendances du monde réel sur lequel doit porter le questionnement; (http://www.influxpress.com/imaginary-cities/ , \href{http://cybergeo.revues.org/1170#tocto1n9?}{cybergeo})

Si le discours scientifique n'a clairement pas cette obligation ludique, il n'en reste pas moins que ce processus de reconstruction crédible est déjà un outil formidable pour questionner les processus à l'oeuvre dans le monde réel \Anote{ruffat_samuel_ville}. Mais cette ambiguïté de lecture a déjà mené à de nombreux malentendus, d'une part envers le grand public (Voir forrester, mais également \Anote{deffuant_debat}) qui pourrait prendre des résultats de simulation pour la réalité avec tout les conséquences que cela suppose, mais également parfois entre scientifiques provenant de divers horizons. Ainsi après la lecture de la critique par \textcite{Chattoe2011} de l'article de \textcite{Yanoff2009}, il ressort toute la difficulté d'évaluer la méthodologie et le travail réalisé autour d'un modèle au travers d'une seule publication, notamment lorsque la fonction cognitive recherchée par les modélisateurs n'est pas décrite explicitement, ce qui provoque aussi ce décalage entre attente du lecteur et le processus réel de recherche qui sous-tend la construction du modèle. \hl{dp: TROP ALLUSIF}

\textit{Doit on se contenter de ce seul mode explicatif ? Existe t il un moyen pour renforcer la confiance dans la capacité explicative des hypothèses ainsi mobilisés ? } 

\paragraph{Justifier des hypothèses par leurs qualités de représentations}
\label{justifier_hypothese}

%% DEBUT - EN ATTENTE DE LA REPONSE DE VARENNE %%
\textcite{Bulle2005} evoque bien l'existence de modèle à cheval entre potentialité explicative et potentialité descriptive. Ainsi \enquote{appliquée aux processus sociaux réels, la simulation peut allier au potentiel descriptif offert par l’imitation d’effets empiriquement observables, le potentiel explicatif que lui confère la mise en œuvre de relations causales effectives. }

A la différence de modèles trop simples qui n'offrent que de maigres accroches avec la réalité, c'est donc par la réintroduction maitrisée de l'empirie dans les modèles de simulation construits que l'on pourrait espérer la mise en route progressive d'un processus de Validation ?

Un tel processus de justification parait complexe, car celui-ci ne peut être concu de façon homogène sans se heurter avec l'objectif même de toute modélisation, qui on le rapelle, n'est pas une construction guidée par la Validation mais une reconstruction mettant en oeuvre une simplification orienté par et pour un but. On ne parle pas d'un modèle comme d'un ensemble d'hypothèses de représentation homogène mais d'un ensemble d'hypothèse aux représentation hétérogènes.

Ce terme de \enquote{simplification} souvent employé reste d'emploi ambigue, la modélisation nécessitant comme le dit \textcite{Haggett1965} non pas tant la mise en oeuvre d'une simplification aveugle, qu'une idéalisation guidé par la volonté de mettre à nu des propriétés du système observé. \textcite{Brunet2000}, pour qui la modélisation est également un processus de recherche, propose même pour éviter toute confusion sur les termes de dénuder la définition de modèle de cette fausse directivité, le modèle devenant dans sa version la plus épurée une \enquote{représentation formalisée d'un phénomène}; le terme \enquote{représentation} intégrant alors toute la complexité sous jacente à une telle formalisation : \enquote{Il va de soi que cette représentation passe par plusieurs filtres, qui tous tendent des pièges : la perception du phénomène, sa représentation, la construction d'un modèle, l'interprétation du sens de ce modèle et la capacité du modèle à rendre compte du phénomène.}

Un point de vue semble-t-il partagé par Franck Varenne pour qui le terme simplification est \blockquote[{\cite{Varenne2008}}]{[...] un glissement d’attribution indu. Puisque l’usage du modèle est relatif (à un observateur et à un questionnement), on ne peut dire que le modèle doit être un objet simple en lui-même ou dans l’absolu. Il convient donc de regarder sous quel aspect exactement il doit apparaître simplificateur, sous quel aspect il devient un outil facilitateur, un outil de facilitation. [...] on comprend déjà qu’un modèle n’est pas ce qui est recherché en tant que tel, mais ce qui facilite la recherche d’information au sujet d’un système réel ou fictif, cela dans le cadre d’un processus à visée de représentation, de connaissance, de conceptualisation, de conception ou encore de transformation. Il est le moyen plus que la fin. C’est pourquoi je m’aventurerai, à partir de maintenant, à user plutôt du terme de facilitation que de celui de simplification [...]}

Comme déjà évoqué par les géographes, ce n'est pas tant \enquote{le modèle} que ce qu'il y a \enquote{dans le modèle} qui nous intéresse \autocites{Sanders2000, Besse2000}.

Seulement comment analyser la pertinence d'une représentation prise en dehors de son contexte ? Les choix intervenant lors d'une modélisation ne répondent pas à une logique universelle pré-établie, et sont motivés et modulés par un ou plusieurs objectif(s) qui n’interviennent pas forcément de façon volontaire pour guider la modélisation. \textcite{Varenne2013} ayant par ailleurs identifié une vingtaine de ces \enquote{fonctions de facilité de médiation} pouvant très bien se cumuler lorsqu’on observe un modèle. Or il me semble qu'une fois rapporté à la structure interne du modèle de simulation, on est bien obligé de constater l'impact que peut avoir cette diversité d'objectifs dans la mobilisation d’une ou plusieurs représentations, dont certaines peuvent être concurrentes, pour une même hypothèse dans le modèle. Est-ce pour dénoter une entité réelle (un agent = un individu, une ville, une innovation ) ? Est ce dans le but de simplifier pour la compréhension ? pour les performances ? pour répondre au principe de parcimonie ? Ou tout à la fois ? (une population agents homogène devenant une équation de croissance par exemple ) Était-ce un choix fait à la suite d’une multitudes d'autre essais (différentes équations plus ou moins représentative du phénomène à considérer) ? etc. Dans le cas d'un modèle de migration inter-ville, il est en effet plus intéressant de mobiliser les populations de façon agrégé si on s'intéresse aux règles intervenant dans la dynamique d'interactions entre les villes, par contre, si il s'agit d'observer l'impact que peuvent avoir des règles de comportements sur ces interactions, ce niveau peut devenir pertinent; cette approche ne chassant évidemment pas la première, au contraire les couplages étant bienvenu. En définitive, il n'y a aucune raison pour que les hypothèses intégrées aux modèles de simulation soit homogènes. Ainsi, pour Franck Varenne, pour identifier à posteriori quels sont les fonctions épistémiques mobilisés, et donc par extension déterminer dans quelle mesure l'intérêt porté à la validation a pu être très diffèrent lors de la construction du modèle (pour un modèle de simulation pédagogique, la validation n’est par exemple clairement pas une priorité ...), il est nécessaire de se poser la question pour chacune des hypothèses représentées dans le modèle de simulation : est ce une dénotation ? une exemplification (métaphores) ?

Normalement tout ces choix devrait être explicités \autocite{Varenne2013b}, ce qui est rarement le cas, vu la complexité d'une tâche qui apelle pour être sérieuse l'analyse d'une activité de raisonement accompagnant le modèle dont les jalons ont bien souvent disparu.

La tendance à la pluriformalisation \Anote{pluriformaliser } permise par les modèles multi-agent ne vient pas non plus faciliter cette tâche, car ces modèles de simulation qui peuvent déjà intégrer -et c'est d'ailleur pour cela qu'ils ont autant de succès- sans problème une hétérogénéité d'échelle, de niveau d'abstraction, de modèles, doivent aussi compter avec l'intégration de formalismes mobilisant des temporalités et/ou des échelles différentes \autocites{Varenne2008,Varenne2012a}. Ces couplages n'étant pas toujours évident, y compris au niveau informatique où des artefacts (c'est à dire l'apparition de mécanismes nécessaire à l'implémentation mais non prévu et difficile à expliquer d'un point de vue purement théorique) peuvent venir rapidement venir perturber les ontologies réalisés en amont. 

Même les modélisateurs ont parfois du mal à s'y retrouver, par exemple il n'est pas toujours évident d'expliquer pourquoi on a choisit de coupler pour certain mécanismes le formalisme agents avec celui des équation différentielle ? Il faut alors comprendre que dans certains cas, c'est aussi ce qui a pu motiver le modèle, l'intérêt de la pluriformalisation étant justement ce qu'il faut démontrer en comparaisons des approches traditionnelles prisent séparément. Plusieurs réflexions ont montrés qu'il s'agissait d'un type de modélisation en devenir et en voie de démocratisation, les formalismes pour la simulation informatiques (multi-agents, micro-simulation, automates cellulaires) ou mathématiques (systèmes dynamiques) utilisés n'ayant jamais eu vocation à s'opposer (approche individu - centré contre approche mathématique traditionnelle) comme on aimerait parfois nous le faire croire \autocites{Sanders2013, Banos2013}. 

\textcite{Varenne2013b} s’intéresse de beaucoup plus près aux effets de cette hétérogénéité interne aux simulations d’un point de vue épistémologique, et c’est d'ailleurs de ces articles sur cette question et de plusieurs échanges privés avec lui qui ont inspirés certaines de ces dernières réflexions. Il nous sera toutefois difficile d’aller au delà sur cette analyse de la \enquote{représentativité des hypothèses fonction des objectifs}, car même si celle-ci est une question passionnante, elle reste un axe de recherche avant tout théorique et en plein développement. Aucun n'exemple concret ne permet pour le moment d'illustrer la forme que pourrait prendre une telle analyse.

Un autre argument vient condamner encore plus fermement l'idée de justifier d'une Validation des modèles basée sur la qualité de représentation de ses hypothèses. Celui-ci a déjà été effleuré en traitant de philosophie des sciences dans la section \ref{sssec:philo_sciences}. Le processus de validation se heurte rapidement à la différence de nature entre les résultats produits par des hypothèses \textit{reconstruites} et le monde réel \Anote{bulle_modele_autonome}. Tout comme le substrat est artificiel, le résultat produit par cette dynamique reste le produit d'un monde reconstruit - \textit{in silico} - L'existence de ce nouveau niveau d'empirie amène les épistémologues comme Franck Varenne à parler ici d'\enquote{expérience concretes du second genre} faisant alors de la simulation une \enquote{quasi-expérimentation} \autocites{Varenne2001, Varenne2007, Phan2008}

On en déduit que quelque soit notre placement sur ce gradient, il est effectivement vain de chercher à valider un modèle en usant d'un quelconque \enquote{seuil de suffisance} caractérisant \enquote{l'injection de réalisme à atteindre qui autoriserait une inférence certaine sur le monde réel}, puisque de toute façon cette inférence s'appuie sur un résultat \enquote{artificiel} forcément discutable \Anote{phan_livet_modele}.

\paragraph{Inverser le problème de la validation pour désengager cet objectif de correspondance au réel}
\label{p:inverser_problematique}

Une autre façon donc de dépasser cette problématique de la Validation est d'accepter le fait que le réalisme des hypothèses ne soit plus vraiment un objectif, mais plutôt la réalisation conséquente d'une expertise qui tient essentiellement de l'angle théorique choisi pour éclairer un problème.

Autrement dit, la confiance établie dans les capacités explicatives des hypothèses choisies ne se juge pas tant dans la comparaison des résultats attendus avec le réel observé, que dans l'exploration du monde crédible ainsi simulé en fonction de critères experts construit sur une observation du réel, dans l'espoir d'en dégager une connaissance qui doit encore être vérifiée \Anote{denise_geopoint}. 

Le problème est ici en quelque sorte inversé, ce n'est plus une qualification directe du réel qui est visé par le modèle, mais le modèle qui est visée par notre compréhension du réel au travers de critères experts. Ceux-ci viennent questionner et mettre en tension ce monde virtuel en lui imposant de nouvelles contraintes, révélant par là même les forces et les faiblesses de nos hypothèses dans le modèle. On oppose dans la construction du modèle \enquote{un jeu d'hypothèses susceptible de produire des résultats attendus}, à la réalité des conclusions apportés par la \enquote{mise en oeuvre effective d'une dynamique}.

Cette situation semble ramener le problème de la \enquote{Validation} à une évaluation \enquote{terme à terme} entre hypothèses et critères devant en rendre compte. 

C’est me semble-t-il ce que voulais dire Frédéric Amblard \textcite{Amblard2006} lorsqu’il parle du rapport liant la détection de comportements de la \enquote{validation interne} à leur utilisation comme support d’une partie de la \enquote{validation externe}.  

\blockquote[\cite{Amblard2006}]{L'analyse de sensibilité, si elle peut s'appliquer pour tester la robustesse des résultats d'un modèle, peut également être utilisée pour tester la robustesse de la structure du modèle. En modifiant les hypothèses réalisées dans le modèle, par exemple en modifiant les structures organisationnelles, le modélisateur obtient des indices relatifs à la stabilité de son modèle et de ses hypothèses. Ces indices lui permettent précisément de jauger l'importance du choix d’une hypothèse et l’influence de son remplacement par une autre sur un aspect particulier du modèle. [...] Une autre propriété importante qu'il s'agit d'étudier au cours de cette étape de validation interne, concerne les classes de comportements produites par le modèle. Les simulations multi-agents produisent ce qui est assez communément appelé des \enquote{comportements émergents }  (voir chapitres 14, 16 et 17), c'est-à-dire des comportements qui ne sont pas exprimables en utilisant uniquement les hypothèses réalisées sur les comportements individuels}.

Deux propriétés qui font ainsi écho à une méthode de la validation externe qui \enquote{[...] consiste à rapprocher les classes de comportements (identifiées lors de la validation interne) à des comportements saillants du système-cible : les faits stylisés.}


\enquote{Ce rapprochement, s’il peut être fait avec des faits stylisés identifiés a posteriori (permettant par exemple de découvrir dans les phénomènes empiriques, des comportements stylisés qui auraient pu passer inaperçus), possède, on le sent bien, plus de force lorsque les faits stylisés sont déterminés avant même la modélisation comme des comportements que l'on cherche à reproduire par le modèle ou dont on se servira comme un critère de validation parmi d'autres (rétrodiction).}\autocite{Amblard2006}

% A CORRIGER
Ce points nous incite également à pratiquer une évaluation à contrepied de la démarche habituelle, alternant validation interne, puis externe. Le modélisateur se saisit un moment de cette légitimité évoqué par \hl{Bulle} en devenant celui qui met en tension cette relation pour construire ses modèles. On met alors de coté un instant la validation interne comme exploration non dirigé des comportements du modèle pour se concentrer sur une exploration, moins complète, ou c'est ce désir de rapprochement qui vient piloter cette fois ci l'exploration des comportements. Les modélisateurs peuvent en effet introduire les hypothèses dans un modèle de simulation dans le but de satisfaire, ou \textbf{de ne pas satisfaire} ces critères. 

En effet on a bien précisé par exemple que l'objectif de correspondance avec les données n'était plus un critère prioritaire dans l'établissement de tels modèles de compréhension, sinon pourquoi ne pas se contenter d'un simple modèle de Gibrat pour expliquer la hierarchisation des systèmes de villes ? 

%Cette inversion soulève de nombreuses remarques que l'on va tenter d'articuler par la suite. 
\hl{Attention tu doit prendre en compte les criteres}
Cette inversion soulève plusieurs remarques. D'une part, on se rend compte que les critères d'évaluation deviennent aussi importants que les hypothèses dont ils sont censés rendre compte. D'autre part, il faut soulever les modalités qui sous tendent cette nouvelle façon de construire de la connaissance. C'est par ce dernier point que nous allons commencer notre analyse.

\paragraph{L'abduction, un phénomène clef moteur dans l'activité de modélisation}
\label{p:abduction}

\input{validationText/abduction}

\paragraph{Quels critères d'évaluation pour quelle mesure des hypothèses ?}
\label{p:critere_evaluation}

\input{validationText/multicritere.tex}

Pour \textcite{Bulle2005} il sera donc toujours nécessaire et légitime de questionner la pertinence des rapports mesurés entre les liens causaux proposés dans le modèle et le ou les critères qui sont censés en rendre compte.

\hl{T:} 
Cette variabilité est à la fois conséquence naturelle du processus de raisonnement, mais également une conséquence logique liés à la nature insaisissable du réel. Toutefois là ou on pourrait voir cet effet comme positif et cumulatif, l'équifinalité est souvent présenté comme un défaut de l'outil et de la discipline. La section suivante essaye de voir les solutions proposés par la communautés des modélisateurs dans la mise en perspective d'un débat récent. Une autre proposition, plus proche de nos pratiques sera ensuite présenté, mais nécessitera de repenser la façon dont sont construit et valorisé des modèles. % dans un cadre d'analyse qui s'appuie sur l'existant pour mettre en valeur les aspects dynamique, cumulatif, et local de cette activité.

\subsubsection{Repenser la question de l'équifinalité}

On a vu dès le départ avec Hermann que la validation était indissociable d'un contexte, et posé de fait la question de la représentativité des hypothèses à celle des critères mobilisés. 

En cherchant comment pouvait-on mesurer de la qualité explicative des modèles réalisés, on s'est apercu que la recherche d'un seuil de réalisme adéquat n'était pas un bon argument pour guider l'intégration des hypothèses sur les entités ou les activités à injecter dans nos modèles.% En développant jusqu'au bout l'argument d'une justification possible dans le choix fait des modélisateurs sur la représentativité des hypothèses, on s'est rendu compte qu'il s'agissait pour le moment plus d'une question épistémologique a posteriori que d'un comportement assumé par les modélisateurs. Peu de modélisateur font aujourd'hui cet effort d'explicitation des fonctions facilitantes associés à chacune des hypothèses en les rapportant au raisonnement accompagnant la construction du modèle.

Enfin, comme il n'est pas non plus possible de garantir une validation empirique terme à terme entre hypothèses et données, il est nécessaire d'accumuler différents critères quantitatifs et qualitatifs non pas pour se rapprocher d'un fonctionnement réel, mais plutot là aussi pour garantir la cohérence d'une \enquote{reconstruction d'un jeu de causalité identifié dans l'observation d'un phénomène} que l'on veut confronter \enquote{aux mesures censés rendre compte de ce phénomène dans la réalité}. Le jeu abductif entre en compte pour encourager ou perturber ce rapprochement entre hypothèses selectionnés et critères mobilisés.

Il a été avancé également qu'une partie des connaissances dégagés durant ce jeu abductif rythmant la construction des modèles était lié au fait que le modèle de simulation servait de laboratoire non pas pour modéliser et confronter le monde réel, mais plutôt pour modéliser et confronter nos a priori théorique sur le fonctionnement du monde observé. A ce titre, les échecs induisent un retour sur la théorie plus stimulant que les réussites, ce qui motive aussi la prise de risque et la créativité dans les hypothèses ou les critères avancés.

Chacun de ces arguments renvoie normalement l'image d'une activité de validation indissociable d'un contexte donné. Pour reprendre les mots de \textcite{Amblard2006} \enquote{[...] les questions pour la validation des modèles ne devraient jamais être abordées en dehors des questions relatives à leurs usages.} 

L'équifinalité vient ici compliquer ce constat, car elle fournit l'image inverse si on n'y prend gare, en facilitant l'idée qu'une construction peut être facilement remplacé par une autre, sans que le contexte ne soit abordé. Le problème n'est pas que cela puisse être vrai ou faux, car comme on va le voir ensuite, la possibilité de rendre compte différemments d'un même phénomène a été intégré depuis longtemps dans les différentes modélisations supportées en géographie, mais plutot que des personnes extérieures à une communautée puissent penser que c'est un défaut des techniques ou des méthodologies utilisés, alors que c'est un défaut propre à l'études des systèmes complexes, et donc également des systèmes sociaux. 

Une entrée par les critiques récentes formulés sur ce cadre d'analyse historique des \enquote{Science Générative} formulé par Epstein peut être un bon exemple pour montrer que l'équifinalité, si on ne la justifie pas, peut grever la crédibilité des modèles présentés. Elle peux même comme on va le décrire dans la section suivante, fournir le support biaisé à un argumentaire qui décrédibilise l'apport explicatif permi par l'utilisation de cet outil en en sciences humaines et sociales. Un groupe de sociologues proposent de répondre à ces critiques par un nouveau cadre d'analyse. 

%Débat CONTE / EPSTEIN, résoudre equifinalite en justifiant d'une causalite
\paragraph{Faire appel à un nouveau cadre d'analyse ?}
\label{p:cadre_analyse}

\input{validationText/cadreAnalyse}

Une autre façon d'éviter ce malentendu, il faut exposer le contexte de création, et par là donner à voir une équifinalité qui se veut constructive et impossible de nier lorsqu'on analyse les modèles.

\paragraph{Sortir de la logique de preuve}
\label{p:preuve}

\input{validationText/preuve}

\paragraph{Reintégrer la dimension temporelle}

\input{validationText/temporel}












------------- VRAC LUNDI



 Une des premières questions auquelle on est tenté de répondre coincide avec la citation d'Amblard. Celui-ci nous indique un rapprochement avec des seuls faits stylisés, mais pourquoi ne pas directement comparer chacune des hypothèses mobilisés avec les critères quantitatif (données) dont on dispose ? 







La démonstration précédente nous indique plusieurs pistes de réflexions.

D'une part l'objectif de réalisation d'un modèle au réalisme uniquement structurel n'a pas de sens, même avec beaucoup d'hypothèses, car elle ne permet en aucun cas de garantir la justesse d'une comparaison entre données empiriques et simulés, et n'offre donc aucun critère d'arrêt pertinent dans l'activité de modélisation.





%Pourquoi ne pas envisager ici une validation externe basé sur une comparaison empirique et terme à terme des hypothèses constitutive entrant dans la structure causale du modèle ?

 


\paragraph{Reprendre le controle dans cette mise en tension}
\label{p:critere_evaluation}

%C'est ce rapprochement entre hypothèses et critères d'évaluation mobilisés qui est le véritable enjeu dans la construction des modèles explicatifs. %Ces critères peuvent être de deux types, quantitatif ou plus qualitatif comme les fait stylisés.


%\textcite{Hermann1967, Hermann1967b} propose d'établir non pas une méthode, mais une série de méthodes complémentaires, dont il détaille pour chacune d'elle les qualités et les faiblesses pour la comparaison entre système modélisé et système de référence. Chaque méthode constitue ce qu'il appelle un \textit{validation criteria}, un type de critère de validation générique dont le choix et la mise en œuvre effective est déterminé par le modélisateur en fonction des objectifs poursuivis.


% A deplacer et a remettre dans le flux au desssus ? 

%On retrouve une idée assez similaire mais peut être exposé de façon moins formalisée chez \textcite{Hermann1967} qui évoque bien aussi la nécessité d’une \enquote{validation multi-critères} interrogeant et renforçant par l'accumulation et la diversification de ces différents tests la crédibilité des composantes internes du modèle.


%Enfin il faut noter que les critères d'évaluation, au même titre que les hypothèses, ne sont pas forcément connus au moment ou l'implémentation du modèle démarre, dont il faut déjà justifier la construction

%Quel est la nature de ce rapprochement ? Enfin, comment peut-t-on \enquote{supporter au mieux} le modélisateur dans son nouveau role d'acteur de cette mise en tension ? 

% Penser à dire qu'il est toujours possible d'inférer sur la réalité, en établissant de nouvelles mesures, mais aussi de nouveaux modèles. C'est pour cela qu'il est important de considérer les modèles de simulation dans une chaine plus globale de construction des connaissances.   








%Il y a donc en permanence dans l'activité du modélisateur l'illustration de multiples tensions qui font de celle ci une expérience parmis d'autres, et nous rapproche déjà d'un point de vue plus proche d'une vision relativiste qu'objectiviste. L'historique d'un modèle se lisant tout autant au travers des choix d'hypothèses exercés par le modélisateur tout au long de son expérience de modélisation, que dans la lecture de l'objet finalisé. Une tension entre d'un coté la volonté d'expliquer des données par un ensemble d'hypothèses explicatives respectant un critère de parcimonie, et de l'autre coté cette volonté naturelle du modélisateur à tenter d'expliciter un maximum de cette variabilité vis à vis de la séries de données dont on dispose, et dont on sais par ailleurs que celle ci est déjà loin d'être neutre, exhaustive ou exempt d'erreurs.

=> Clementine avait une phrase bien pour ca ! (voir fiche)

Autrement dit la réponse aux questions posés au modèle de simulation, et donc par extension à nos connaissances incomplètes sur le fonctionnement supposé du réel dans la reproduction d'un phénomène donné, se trouve dans cette mise en tension volontaire entre hypothèses du modèle et critères d'évaluations mis en place pour en rendre compte.

Il semble que cette mise en tension se satisfait assez bien d'un cadre d'analyse basé sur l'activité de modélisation, ou les critères et les hypothèses ne sont pas tous nécessairement connu à l'avance, ni introduit de façon simultanée. Ce qui laisse la place au cours de cette confrontation à l'avénement d'une certaine surprise, à même de produire une connaissance, et de guider le choix des modélisateurs à chaque nouvelle étape dans la construction du modèle. 

% Les critères toutefois entretiennent un lien avec les hypothèses dont ils sont censé rendre compte, on peut donc imaginer que la parcimonie exprimé dans la construction des modèles puisse faire en lien des critères porteurs de cette connaissance exprimés sur le comportement du modèle. 

% Une remarque d'autant plus valable lorsque on sais que cette histoire se construit en confrontation avec la construction et la mise en oeuvre progressive des critères constitutif du système ciblé.

% Ce qui pose effectivement toujours la question de la nature des connaissances attendues dans une telle perspective.





% La question des modes de constructions
%Une solution élégante à été proposé par plusieurs auteurs, sous la forme d'une famille de modèle.


%, pas seulement en sociologie, mais également en géographie ou le spatial et le temporel donne encore un autre poids à cette grille de lecture. 

\paragraph{Montrer l'équifinalité dans l'évaluation des modèles}

Là ou ce cadre d'analyse propose de réaffirmer le statut explicatif des hypothèses insérés dans les modèles par un ancrage empirique plus important, une parcimonie, et surtout une épistémologie admettant l'existence possible d'une explication même si la chaine de causalité s'avère partielle ou lacunaire, nous avons suivi une toute autre trajectoire dans notre équipe.

Il a en effet été choisi de justifier cette équifinalité non pas en l'intégrant dans un nouveau cadre d'analyse, mais en la faisant plutôt apparaitre de façon explicite comme le résultat de nos démarches de raisonnement accompagnant la construction des modèles. Il ne s'agit plus de produire des modèles de simulation comme le résultat d'une histoire, qui resteront de toute façon toujours critiquable, et dont on ne verra jamais l'historique de construction, au profit de trajectoire dans des familles d'hypothèse constitutive des modèle qui intègre et donne justement à voir cette variabilité et ces aller retours possible dans les propositions.

Il y a je crois plusieurs avantages à voire dans cette solution, car elle permet d'intégrer la transformation des modèles dans le temps et dans les disciplines, tout en replacant la discussion comme un élément important dans la validation. 

**************
***************

Faisant cela, l'autonomie du modèle se diffuse à l'autonomie des démarches, des outils qui la composent, et des personnes qui les manipulent.

Une trajectoire des modèles déjà constaté dans nos pratiques de modélisation \autocite{Banos2013}, l'inter-disciplinarité inhérentes aux systèmes complexes cautionnant ces migrations pour éclairer des objets complexes à l'aube de cette diversité de points de vues, par l'emploi de nouvelle théories, de nouvelles échelles de temps et d'espace, et impliquant la transformation, au delà du modèle, de la démarche accompagnante qui permet son évaluation.

Quelques auteurs progressent sur cette voie en sciences humaines et sociales, mais cela reste des cas relativement isolés \autocite{Ngo2012} \autocite{Schmitt2014} \autocite{Heppenstall2007} \autocite{Stonedahl2011a} entre autres.





et Rouchier2013


Quelque chose que les sciences humaines et sociales savent faire.

Argumentation denise...


%%%%%%%%%%%%%%
Nécessaire de prendre en compte l'activité de construction :
- construction des hypothèque 
- construction des critères



Comme on l'a déjà discuté, la modélisation pour l'explication à besoin d'être confronté aux données si elle veut être prise au sérieux \autocite{Banos2013}.






Ces deux éléments permettent de relativiser cette problématique de l'équifinalité, qui n'est alors plus percu comme un problème sapant l'explication, mais comme une richesse d






De plus, il faut penser que le fait d'accepter qu'aucune causalité ne peux être avancé, c'est se condamner à la seule manipulation des corrélations statistiques, avec le risque de tomber dans un point de vue relativiste souvent clamé par l'approche herméneutique.






They look for an informative explanation, which incorporates additional understanding of the level of reality that the phenomena of study belong to. In our example, this means an explanation adding further understanding of social individuals.


































++ famille de modèles ++ va avec
++ famille de critères ++ 



%- Les problèmes identifiés comme des problèmes de données liés aux ABM dans les Anasazi par Grüne-Yanoff sont applicables en réalité à toutes les sciences humaines : l'absence, l'incomplétude, l'incertitude des données, et l'impossibilité de mesurer des phénomènes empecherai l'obtention d'une chaine de causalité complète, l'inférence abductive et la possibilité d'une explication concurrente renvoie automatiquement à une explication causale partielle, et rend la possibilité d'une chaine de causalité complète impossible.
%- les hypothèses en entrée n'ont jamais été falsifié pour approcher les données en sortie, comme le suppose Grüne-Yanoff.
 

tout comme d'ailleur cela n'avait pas convaincu ...  qui voyait dans cet multiplicité de combinaisons possible un aveux de faiblesse dans la capacité causale de ces modèles. 





L'équifinalité offre ce support pour confronter nos théories sur un objet social qu'il est impossible de tout façon impossible de voir dans son unicité.


Si on comprend les enjeux d'un tel projet, se pose alors les moyens de sa réalisation; la systématisation des évaluations avait déjà été annoncé comme un outil devant être mobilisé dès la pose des premières hypothèses, mais elle devient absolument nécessaire pour rendre cette fouille de modèles réaliste, et passé peut être à une échelle supérieure, celle de la construction et de l'étude de famille de modèles comme premier élément de réponse intégrateur de la pluralités des points de vues.

A ce titre, le recours au calibrage, et la recherche de cohérence interne dans les dynamiques pourraient passer pour une tentative de mieux définir par ce biais les processus en jeu dans un contexte réel. Pour \autocite{OSullivan2004} cet argument est encore un leurre, car toujours au vu de l'équifinalité, si ces procédures améliorent bien la connaissance du modèle, absolument aucune garantie ne peut être donnée sur l