% -*- root: These.tex -*-

\section{Principes à respecter pour la construction d'une plateforme }
\label{sec:constante_problematique}

%Cette réflexion menant à la construction d'une démarche systématique pour l'évaluation et la construction de modèle de simulation doit certes être mené dans le cadre d'une amélioration de nos pratiques, mais nous avons vu que cet effort n'avait pas pour vocation première l'établissement d'un standard. En effet, la diversité de ces même pratiques rend impossible et réducteur une telle approche. 

% L'impossibilité d'une démarche englobante universelle

Dans la section précédente, un historique de la validation a permis de voir quelles limites récurrentes pouvaient expliquer la difficulté de développement des pratiques de validation. Dans cette section, il s'agit d'établir des principes qui prennent à la fois en compte l'analyse précédente, tout en la projetant dans un contexte de recherche plus actuel, marqué par le retour à des critères de scientificité plus stricts. 

\subsection{Le choix d'une plateforme intégrée}
\label{ssec:choix_plateforme_integree}

Tel qu'on a pu le constater dans le chapitre précédent, l'évaluation d'un modèle s'avère être une opération hautement contextuelle (section \ref{ssec:triple_lecture}) et incrémentale (section \ref{ssec:evaluation_construction}). 

Le modèle de simulation tant qu'il se définit comme un objet dynamique support d'une activité de recherche (section \ref{p:autre_def_modele}) possède une dimension historique. Rendu public, celui-ci échappe alors à ses créateurs,s'autonomise et développe une histoire dont le succès se mesure à l'aube des trajectoires multiples et transformantes qu'il subit \autocite{Banos2013a}. Ainsi n'a-t-on pas déjà évoqué l'histoire de modèles devenus dans leur discipline des mécanismes de référence, point de départ de toute modélisation : daisyWorld \autocite{Dutreuil2013}, Schelling \autocite {Bulle2005}, Sugarscape, Anasazi, et plus proche de nous, en géographie le coeur commun à la famille des modèles de simulation Simpop.  

L'emploi d'un unique cadre formel capable d'anticiper tout autant la possibilité de cumul et la diversité des objectifs, que celle des pratiques des modélisateurs parait de ce fait difficile sinon impossible à mettre en place.

Depuis l'apparition de la simulation, et avec elle le \enquote{problème de la validation}; la nécessité d'une méthodologie, d'un protocole, bien que régulièrement évoqué, subsiste malgré l'évolution technologique qui touche le substrat de nos modélisations. Preuve supplémentaire qu'il existe dans ces questionnements des invariants qui ne peuvent pas être capturé dans une seule lecture technique, ou méthodologique de ce problème (section \ref{sssec:communautes_jasss}).  

%que sur  celle ci ne doit pas être  relativement peu de méthodologie clef en main qui s'attaque de front à cette problématique, la plupart se bornant seulement à l'établissement de guides de bonne pratiques, ou de listes d'outils (mathématiques, statistiques, informatiques) disponible.

Parmi les tentatives les plus récentes d'approche de ce problème, la méthodologie POM (\textit{Pattern Oriented Modelling}) \autocites{Grimm2005,Grimm2011} proposée en écologie par Grimm et Railsback vient compléter les précédents efforts de standardisation déjà réalisés avec ODD \autocite{Grimm2010}. Celle-ci propose aux modélisateurs de construire des modèles de simulation de façon incrémentale en partant d'une hypothèse nulle. Le passage d'un incrément à un autre se fait par l'injection de critères permettant de garantir la crédibilité du modèle au fur et à mesure que celui-ci se complexifie. Bien que non rattaché dans l'absolu à un support informatique en particulier, l'auteur s'appuie pour transmettre son message pédagogique sur l'utilisation de Netlogo et de ces outils intégrés pour l'exploration comme le \textit{Behavior Space}.

Si la méthode peut servir à former les jeunes modélisateurs à de bonnes pratiques dans le futur, elle reste contraignante pour qui modélise déjà en suivant sa propre méthodologie. Autrement dit, je ne pense pas que l'injection forcée d'une méthodologie dans des pratiques de modélisation établies depuis des années soit une bonne solution en première instance. Toute nouvelle approche pour être réussie doit avant tout je pense encapsuler et s'adapter à minima aux pratiques existantes des modélisateurs, tout en leur permettant d'évoluer par la suite si nécessaire. Reste que les modalités d'une telle approche doivent encore être raffinée \textit{Oui mais quelles sont ces pratiques, et qu'est-ce qui dans leur mise en oeuvre empêche une évaluation plus systématique des modèles ? Comment peut-on les faire évoluer sans les imposer de force ?}

L'approche de Grimm et Railsback, si elle fournit effectivement une méthodologie efficace de construction de modèle, dont on perçoit qu'elle est à bien des égards similaire à celle expérimentée dans notre équipe de modélisation (\hl{cf ref passage Marius dans chap précédent}), il existe toutefois une dissonance entre la méthodologie proposée et le support informatique véritablement adapté. Si Netlogo est effectivement choisi par les auteurs pour sa valeur d'outil pédagogique, ceux-ci sont, je pense, tout à fait conscients que ce choix ne permet pas en l'état de développer de façon réaliste une calibration basée sur une approche multi-critères dans le cas de modèles plus complexes tels que le laisse supposer POM. \hl{Ajout citation p233 et page 313 et 315}

Autre initiative remarquée, celle menée par l'équipe dirigée par Wilensky connut principalement pour avoir développé le simulateur Netlogo. Parmi les papiers écrit par Wilensky ces dernières années \autocite{Wilensky2007a} plusieurs se rapport à mettre en avant - comme d'autre l'ont fait dans la communauté \hl{ref Epstein, etc}- l'importance de \enquote{pratiquer la reproductibilité} pour nous et pour les autres. Un des objectifs visés étant la constitution d'une communauté scientifique capable de dégager de nouveaux savoirs par le partage et la discussion collective des modèles. Une recette que Wilensky a appliqué avec succès dans la reproduction de nombreux modèles afin de les faire figurer dans sa plate-forme, et qu'il faut évidemment mettre en perspective des principaux traits faisant toute la valeur du simulateur Netlogo. 

Avec Stonedahl \autocites{Stonedahl2011, Stonedahl2011b, Stonedahl2010}, il explore cette fois-ci une autre dimension de la validation en s'attaquant à l'exploration automatique des modèles de simulation écrits en Netlogo. L'outil \textit{Behavior Search} ainsi développé par \textcite{Stonedahl2011a} s'appuie sur des méta-heuristique, principalement de la famille des algorithmes évolutionnaires. Cet outil se place volontairement dans la continuité de l'\enquote{esprit Netlogo}\Anote{stonedahl_netlogo}, à savoir offrir des outils à la fois suffisamment simples d'accès pour s'adapter à un public \enquote{débutant en modélisation}, tout en étant suffisamment complet, évolutif, pour intéresser et accompagner les recherches d'un public essentiellement scientifique. Les outils acquièrent avec leur diffusion à une standardisation qui leur permet de toucher à cette dimension sociale constitutive d'une part de la validation.

L'accroche d'un public aux compétences variables, qu'ils soient experts ou débutants, est un enjeu tout à fait compris par les modélisateurs. La plus ancienne des librairies multi-agents \textit{Swarm} était déjà pensée par Langton comme une étape supplémentaire vers la démocratisation des outils. Un saut qui a permis de fédérer une première communauté, mais qui n'était pas suffisant pour toucher un public de non-programmeurs. Le jumeau scientifique de la plateforme pour enfant StarLogo, Netlogo, a permis ces dernières années de redonner une part d'indépendance aux chercheurs des sciences sociales dans la manipulation de leur objet de recherche, cet outil permettant de concrétiser à moindre cout et de façon quasi instinctive le contenu de discussions scientifiques dans un modèle exécutable tangible. Véritable outil d'accompagnement permettant à tout scientifique qui le supporte, de concrétiser et de communiquer une idée au travers d'un modèle dans un temps record. On se rapproche ici d'un système de communication ou le cout d'entrée est très faible par rapport aux gains supposés. 

Mais, si Netlogo répond de façon parfaite à cette nécessité de prototypage rapide et peu couteux, un scénario tout à fait adapté pour découvrir la modélisation; il ne permet pas par contre de répondre à un scénario pourtant classique rencontré par les modélisateurs souhaitant faire évoluer leur modèle sur le temps long au-delà d'une certaine complexité. Ainsi, tant d'un point de vue algorithmique, que du point de vue des ressources informatiques nécessaires à l'exécution et à l'évaluation de modèles, Netlogo ne permet pas de supporter une montée en complexité pourtant naturelle dans le cadre de tels projets. 

On sait également que la diversité et la complémentarité des approches sont un point central dans l'étude des systèmes complexes; or si Netlogo donne effectivement à voir cette diversité par la présence d'une large bibliothèque de modèles, celle-ci n'est abordé que dans une seule dimension, celle du modèle, et sous un seul format, celui de Netlogo. C'est il me semble le désavantage difficile à éviter de tout approches visant une forme de standardisation. Or chacune des disciplines dispose de ses propres outils, de ses propres formalismes, de ses propres formats que Netlogo serait bien en peine de vouloir reproduire à l'identique. Cette diversité d'approche caractéristique des systèmes complexes dépasse qui plus est largement largement le cadre de la seule description du modèle et touche également l'environnement qui peuvent graviter autour de lui. Choisir Netlogo c'est prendre le parti d'un formalisme qui donne accès à une communauté, à un ensemble d'outils, mais qui ne permet pas d'exploiter au mieux les apports de diversités propre aux pratiques de modélisation de chacune des disciplines. 

Au travers de ces deux exemples, on a mis en valeur quelques points d'accroches montrant la difficulté qu'il y a à établir un cadre plus ou moins formel et englobant capable d'articuler l'ensemble des problématiques se rapportant à l'évaluation et à la construction de modèle de simulation.  


%  se présente par un ensembles de couplage entre des outils conçu sur une base autonome et standard;

\hl{--en cours--}

Autrement dit, ce projet s'inscrit dans un objectif double, il s'agit à la fois de garantir l'indépendance et la réutilisation des outils dans de multiples configurations, tout en problématisant leur utilisation dans des constructions méthodologique (ou cas d'utilisation) que nous jugeont pertinent pour l'exploration et la construction de modèles en géographie. De ce fait ils participent à l'évolution d'une plateforme appropriable par tout les points de vues, non réducteur car flexible dans le cadre de nos pratiques, et appuyant en plusieurs points cette dimension collective pour la construction et l'évaluation de modèle.
% Construction = Evaluation 

Moto : \enquote{Si je ne peux pas évaluer le modèle à ta place, je peux par contre te donner les meilleurs outils pour que tu puisse le faire} 
= en te donnant les moyen d'etre autonome cad
= en te donnant les moyens de mutualiser
= en te donnant les moyens de t'informer 
Deux axes qui recoupent : reproductibilité (pour moi, pour les autres) , flexibilité (pour moi, pour les autres), puissant ( pour moi, dans l'échange), dynamique (pour moi, pour l'échange)

But a atteindre, 
> utilisation inter-disciplinaire, 
> ouverte aux débutant, ouvertes aux experts
> standardisation interne à minima, externe si l'outil est amené à se développer.
=> Plateforme intégrative 

L'accès à l'outil informatique pour la construction est en voie de démocratisation, comme en témoigne de nombreux indicateurs, tant sociologiques extérieurs (génération petite poucette de Michel Serres), que politique (programmation de formation américain), qui s'exprime par le développement et la démocratisation de plateforme de programmation accessible à tous : Scratch, Blocky, Vixle (https://www.kickstarter.com/projects/realityfoil/vixle-a-game-engine-for-everyone)
Un support qui maintenant date des premiers travaux du MIT avec Logo/StarLogo ... etc

\paragraph{Un outil de \textbf{construction} et d'\textbf{exploration} de modèle}

D'un point de vue utilisateur, on peut considérer l'existence d'au moins deux modes d'exploration auquel on attribue des objectifs très différents. L'exploration dite \enquote{immédiate} permet de controler et de visualiser le comportement du modèle de simulation en temps réel via l'utilisation des outils mis à disposition par le simulateur support du modèle de simulation. On pense par exemple aux \enquote{moniteurs} et autres \enquote{plot} temps réels mis à disposition de l'utilisateur dans le simulateur Netlogo. 

Si ce mode d'exploration peut être apparaitre dans un premier temps comme un moyen de vérification adapté, la complexification progressive du modèle va mettre très rapidement l'opérateur humain en difficulté. Le comportement non-linéaire typique des modèles de simulation en système complexe ne permet pas d'envisager une exploration manuelle exhaustive des comportements; on peut citer plusieurs raisons à cela. En effet l'opérateur va voir son expertise rapidement mise en cause par l'ajout cumulatif de mécanismes, et paramètres induisant des effets imprévisibles dans la dynamique du modèle. Avec pour conséquence immédiate de masquer les défauts de conceptions, qu'ils concernent le 

 vérification superficielle et très rapide du bon fonctionnement général du modèle, que cela d'un point de vue informatique (absence de bug), ou du point de vue conceptuel. 

Un autre niveau d'exploration consiste à analyser à posteriori les données obtenues sorties de simulation, l'objectif n'étant plus le controle cartographier par le biais d'outils adaptés les comportements en sortie de tout modèle de simulation de type agent. 

Dans un premier scénario, le \enquote{modèle} et \enquote{l'exploration de modèles} sont considérés dans un  comme deux objets indépendants, c'est à dire dont le développement peut tout à fait être dissociés. Le choix fait ici d'un couplage faible entre les deux objets d'études permet de garantir l'indépendance du modèle de simulation vis à vis de l'exploration, et inversement. Il en résulte une forme de généricité qui permet d'envisager l'application de tout type d'exploration envers tout type de modèle de simulation, c'est un premier point fort de la plateforme, un coût d'entrée qui se veut minimum pour l'utilisateur, quelque soit l'état d'avancement de son modèle de simulation.

Dans un deuxième scénario, plus dynamique, la plateforme est utilisé comme support à la création du modèle de simulation. On s'interesse alors au dialogue entre 

L'activité de modélisation mobilise un dialogue étroit entre le modèle et ces deux modes d'explorations. Toutefois, on estime que le deuxième mode est le seul qui permette à l'heure actuelle une évaluation des modèles satisfaisante aux yeux des critères scientifiques. Un point détaillé par la suite. \hl{(pourquoi ? )}

De ce dialogue entre modèle de simulation et exploration du modèle nait l'activité de modélisation, la seule qui puisse ici déboucher sur un modèle évalué.

Cette activité de dialogue entraine une relation de dépendance temporaire entre ces objets, qui permet à la fois d'envisager l'amélioration du modèle de simulation au vu des connaissances acquises dans l'exploration, mais également d'envisager l'amélioration, la standardisation ou la spécialisation des méthodes d'exploration au vu des résultats retournés. 

 selon que l'on veut développer de nouvelles méthodes d'analyses . qui une fois mobilisés dans l'activité de modélisation 

\paragraph{Le support de niveau de dialogues différents}

Dans les modes opératoires de construction de modèle, deux \enquote{moments} théoriques (dans le sens ou guidés par des objectifs différents : 

a) Réduire le temps entre l'implémentation de deux prototypes, se rapprocher le plus possible d'une expérience de pensée qui peut être partagé rapidement. Les outils se font le prolongement d'une discussion scientifique, et privilégie donc une prise de controle rapide et facilement partageable (aprentissage aisé, immédiateté d'implémentation et d'execution, support visuel fort pour la discussion).

Un bon exemple de logiciel adaptés à cette utilisation est Netlogo.

b) Réduire le temps d'execution du modèle pour accélérer l'exploration du modèle : 

Contrainte identifié : perte de controle sur le modèle lié à la nécessité d'intermédiaire => tout le monde ne dispose pas d'équipe inter-disciplinaire sous la main.

Objectif : Pour le moment il n'existe pas vraiment d'intermédiaire efficace sur les deux plan permettant une transition aisé (relogo ?), pourtant l'expérimentation nécessite rapidement un accès à une ressource informatique importante, il est donc important de pouvoir découpler ces modes opératoires de l'utilisation effective des expérimentations.

--
%FIXME : Est ce que les points sont hierarchiques ou pas ? 

En admettant que la démarche de construction de modèle soit équivalent à son exploration des modèles autour du principe d'évaluation, l'évaluation devient un élément indissociable de notre démarche de construction des modèles, impose pour être réalisé la mise en oeuvre et le respect d'un certain nombre de principes que la recherche est censé organiser : Collectif, Dynamique, Flexible, Puissance, Reproductibilité, Extensibilité. 

\paragraph{1 - Collectif}

> Cas d'analyse de plateforme ayant réussi cette transformation en communauté dans le domaine de la modélisation : Netlogo.

L'ouverture au collectif est la première des conditions de réalisation de notre plateforme, car c'est uniquement celle ci qui permet d'envisager à terme une standardisation des pratiques chez les géographes modélisateurs. % on se base sur les exemples existants, de plateforme intégrés.

La capacité à pouvoir échanger, et donc à faciliter les échanges avec les autres scientifiques apparait comme la règle minimum à respecter dès lors qu'on accepte de voir le processus de construction et d'évaluation des modèles à cheval entre objectivité scientifique et résultat d'un processus social. 

Par collectif, on entend cette discussion à la fois interne lorsqu'il s'agit de construire l'expérience dans le cadre des pratiques du laboratoire, mais aussi discussion externe, celle qui échappe en partie aux créateurs du modèle, dès lors qu'il s'agit d'afficher et de confronter l'expérience aux yeux des pratiques extérieures.

On entend également la capacité à acceuillir des niveaux de discours différents, qui vont de l'utilisateur débutants à l'utilisateur expérimentés.

Objectif : Définir une plateforme permettant de supporter dans un premier temps, et de catalyser dans un deuxième temps, cette discussion collective, en usant d'outils adaptés. 

% Voir le contenu du modèle (janet)
% Voir le contenu de l'expérimentation (open mole)

\paragraph{2 - Dynamique}

La construction et l'experimentation autour du modèle sont des activités toutes deux incrémentales, ce qui suppose d'organiser les aspects collectif autour 

Nous avons vu dans la section précédente que le modèle de simulation et le groupe d'expérimentations caractérisant ce modèle sont tout deux des objets résultat d'une activité de recherche opérant dans un dialogue mutuel, et dont le contenu initial est connu mais pas forcément le contenu final.

% nottament dans le cadre des systèmes complexes, ou il n'y a pas d'ensemble finis d'indicateurs mobilisable pour borner notre recherche.

Ces choix qui touchent l'ensemble de ces catégories sont étalés dans un temps qui est celui de la construction du modèle, qui ne peut en aucun cas se résumer à un produit final. 

Objectif : Définir une plateforme permettant de supporter par des outils adaptés une discussion collective focalisé en tout temps et pour tout objet intervenant dans la constitution de cette expérience. Le terme supporter renvoie ici tout autant à la présentation, à l'execution, et à l'échange de l'expérience.

\paragraph{3 - Flexible}

La flexibilité est induite des demandes du collectif, interne ou externe.

La trajectoire d'une expérience se définit dans ces deux cas à la convergence de multiples prises de décisions dont la principale influence est le ou les champs scientifique d'application visés par les modélisateurs : choix d'une question déterminé par le champs scientifique, d'un sous ensemble de mécanismes choisis pour répondre à cette question, d'un sous ensemble de formalismes et de niveau d'abstraction hétérogènes, d'un sous groupe d'indicateurs choisis pour mettre en valeur des résultats amenant une réponse à cette question, et d'expérimentations choisis pour évaluer le comportement du modèle fonction de ces derniers indicateurs. 

Le modèle étant mobilisé pour des fonctions épistémiques qui bien souvent se recoupent, aucune de ces catégories n'echappe lors de l'activité de construction à une forme de redéfinition caractéristique de la dynamique de construction. 

Que cela soit dans une trajectoire d'évolution prévue ou imprévue, tout ou partie des constituants de ces catégories sont amenés à être révisé fonction des axes sur lequel le modèle est amené à se déplacer : déplacement sur un axe disciplinaire, déplacement sur une échelle géographique différente, déplacement sur une échelle de complexité pour la représentation du système cible, etc.

Objectif : Définir un outil permettant de supporter une discussion collective en tout temps et pour tout objet intervenant dans la constitution de cette expérience. 

\paragraph{4 - Puissance}

Ce point fait écho aux limitations d'une part d'accès à la ressource informatique brute (existence d'une ressource), d'autre part aux contraintes liés à son utilisation effective (couplage entre expérience et puissance disponible)

L'accès à une ressource informatique doit à tout moment être en phase avec le développement de l'expérience, hors celle ci connait des modes d'expression différents qui oblige à penser un découplage entre modélisation et expérimentation.

L'accès à des ressources informatiques, compatible avec une utilisation collective, dynamique, et supportant l'enrichissement en tout point

(4 - 1) L'accès facilité à la ressource, quelque soit le public cible
(4 - 2) le niveau d'avancement de l'expérience,
(4 - 3/5) les composants qui constituent l'expérience,
(4 - 6) avec la garantie de pouvoir remobiliser cette ressource 


\paragraph{5 - Extensibilité}

La possibilité pour les scientifiques de prendre en main leur outils tout en garantissant l'intégrité de l'ensemble des points précédents.


> Cas d'utilisation en général de la boucle vertueuse entre outils et standardisation d'outils : GeoDA, analyse stat

\paragraph{6 - Reproductibilité}

La reproductibilité \autocite{Sandve2013} d'une expérience et de son empreinte temporelle induit la possibilité pour le collectif de rejouer l'ensemble des étapes ayant menés à la construction de l'expérience, ce qui suppose le versionnement de l'ensemble des constituants de la démarche, du support technique au résultats, en tenant compte des contraintes imposés par les points précédents.

(6 - 1) suppose la mise à disposition du collectif de cette empreinte temporelle, ou d'un instatané de cette empreinte temporelle
(6 - 2) suppose la possibilité de rejouer la trajectoire et 
(6 - 3) suppose la possibilité de repartir de n'importe lequel des embranchements, et de modifier un ou plusieurs des composants pour éventuellement le republier (6 - 1)
(6 - 4) suppose la possibilité d'accéder à une puissance de calcul supposé compatible avec l'expérience
(6 - 5) suppose la possibilité d'ajouter des composants à l'expérience en tout temps

Le support d'un tel point est évident l'objet d'un énorme travail sur la plateforme.


--

a) La reproductibilité des expériences suppose 

a) De maintenir le lien entre un instantané d'un modèle et les expérimentations associés, b) De posséder l'ensemble des versions des modèles et l'ensemble des versions des expérimentations associés

Le couplage entre les deux reproductibilité induit la possibilité de reproduire les résultats de toute expériences, en tout temps et pose évidemment des question techniques importantes.

Difficile à décrire de façon générale ces grand concepts doivent être projeté sur nos pratiques de construction des modèles pour correspondre à une réalité opérationelle.

--

Dans un premier temps, et pour correspondre à un état de pratique tel qu'il est le plus souvent décrit dans la littérature, deux groupes d'activité ont été isolé. L'activité de modélisation d'une part, qui comprend l'ensemble des activité nécessaire à la construction des modèles, et d'autre part l'activité d'expérimentation qui comprend l'ensemble des activités pour évaluer les modèles ainsi construit. 

%L'expérimentation, tel que décrite par {Amblard2003} et reprise sur une idée de {Wagner} constitue un mode de production de connaissance dont la mise en œuvre est motivé pour la construction et l'exploration du modèle. Par « mode de production de connaissance », il faut comprendre qu'il existe plusieurs façon de produire une connaissance permettant l'évaluation du modèle, c'est à dire sa construction : techniques d'analyses de sensibilités, algorithme génétiques pour le calibrage des paramètres, plan d'expérience, etc. 

%L'évaluation des modèles, qui consiste en une accumulation de ces différentes phases d'experimentation guidé par l'objectif d'une meilleur compréhension du modèle, doit devenir un autre objet que le processus linéaire tel qu'il est souvent décrit, avec un début et une fin.

Nous verrons que ce cadre d'analyse ou les deux activités sont amenés à dialoguer pour la bonne construction du modèle est amené à évoluer par la suite, pour concrétiser le passage d'une évaluation des modèles linéaire à une évaluation des modèles non linéaire qui se rapproche plus de l'activité réelle de modélisation.

Le modèle est un produit résultat d'une activité de recherche à un instant t, et qui une fois mis à disposition d'une communauté scientifique, devient objet autonome dont la trajectoire bien qu'impossible à déterminer, doit être envisagé par des outils d'accompagnement permettant de catalyser et de formaliser les discussions.

Autonomie révèle la modélisation comme une expérience résultat d'une activité de recherche

Les modèles de Schelling, Sugarscape, Anazasi sont des exemples de modèles ayant étés repris, discutés de multiples fois. 

Autant de thématiques remisent à l'ordre du jour depuis quelques années du fait de scandale touchant aussi bien les sciences naturelles que les sciences sociales \autocite{OpenScience2012}. 

Cela sans compter la problématique de sauvegarde \autocite{Vines2013} \autocite{Turner2013} et de mise à disposition pour reproduction des expérimentations réalisés sur les données, les modèles et les expérimentations autour des modèles. Une problématique qui dépasse largement le cadre des sciences humaines et sociales et touche l'ensemble des sciences, et plus particulièrement la biologie. 

Cette remarque vaut dans l'ensemble des sciences, dont on prend conscience depuis quelques années du retard sur la question, des sciences naturelles \footnote{Voir le numéro spécial de \href{http://www.nature.com/nature/focus/reproducibility/index.html}{@Nature} en biologie} jusqu'à la psychologie, les  en avance sur la question car durement touché par des scandales ces dernières années \autocite{Steen2011}, mais aussi en modélisation en science sociale, ou la question est abordé depuis de nombreuses années via des groupes de travail et des publications \autocite{Hales2003} \autocite{Rouchier2013}.

De nombreux outils et guides méthodologiques \autocite{Prlic2012} \autocite{Bourne2013} \autocite{Goodman2014} \autocite{Sandve2013} sont en train de voir le jour pour assurer ces aspects de reproductibilité (regroupé le plus souvent sous le label \textbf{openScience} \footnote{Des fédérations tels que \href{http://opensciencefederation.com/}{openScienceFederation} ont récemment vu le jour, on peut suivre les actualités sur le sujet sur twitter \href{https://twitter.com/openscience}{@openScience}}), tant au niveau des plateformes de publication de modèles 
\footnote{\href{http://www.openabm.org/}{@openABM} \href{http://modelingcommons.org}{@modelingCommons}}, de revues 
\footnote{\href{http://www.nature.com/scientificdata/about/}{@Nature} \href{http://www.elsevier.com/physical-sciences/computer-science/executable-papers}{@Elsevier} et en géographie \href{http://cybergeo.revues.org/}{@Cybergéo}}, généraliste 
\footnote{On notera \href{https://authorea.com/}{@Authorea} \href{http://figshare.com/}{@figShare} \href{http://www.activepapers.org/}{@ActivePapers} \href{http://datadryad.org/}{@dataDryad} \href{http://http://thedata.org/}{@dataVerse} \href{http://www.runmycode.org/}{@runMyCode} \href{http://zenodo.org/}{@Zenodo}}, qu'au niveau des plateforme outils support de modélisation 
\footnote{\href{http://www.openmole.org/}{@openMole} \href{http://www.taverna.org.uk/}{@Taverna} \href{https://kepler-project.org/}{@Kepler} \href{http://galaxyproject.org/}{Galaxy}} ou de protocoles 
\footnote{\href{http://www.protocols.io/}{@Protocols.io} \href{https://www.hivebench.com/}{@HiveBench} \href{http://www.nature.com/protocolexchange}{@Nature}}. 



%A ce sujet, il existe une histoire drôle chez les informaticiens, qui peuvent être régulièrement confronté à des états de l'art comportant pléthore d'approches (méthodologique ou technique) pour la résolution d'un même problème. Ainsi l'informaticien zélé, acteur de notre histoire, allume son ordinateur en arrivant dans son laboratoire et part à la recherche d'une solution pour son problème du moment. Mécontent de ne pas trouver un outil satisfaisant pour son problème à la fin de sa journée, celui ci se dit alors dans un éclair de lucidité " Tentons de créer une nouvelle méthodologie pour unifier toute ces approches hétérogènes en une seule !". Ce n'est que quelques mois plus tard, et au terme d'un développement difficile mais enrichissant, que la solution prend finalement forme. A ce moment là, force est de constater que ce ne sont plus 14 mais 15 solutions concurrentes qui s'affronte alors sur le marché des méthodologies pour la résolution de ce problème. Moralité ? Projeter la construction d'une n-ème méthodologie dans une volonté unificatrice (et donc forcément réductrice) peut certes être un exercice constructif (le protocole ODD qui tente d'unifier la description des modèles est en ce sens une expérience intéressante), mais force est de constater que celui ci a peu de chance d'enclencher le processus de standardisation tant attendu, d'autant plus lorsque cet effort s'exerce dans un cadre largement inter-disciplinaire dont les frontières tant sur les aspects méthodologiques que techniques ne peuvent pas être imaginé/intégré par une seule et même personne.

Sur ce dernier point, une première réflexion révélatrice de cette expérience a ainsi été mené par Thomas Louail et Sébastien Rey au laboratoire Géographie-Cités en 2010 \autocite{Louail2010}. L'objectif de ce travail était de lever les limites des méthodologies et outils existants autour des modèles de la famille de modèle Simpop2 afin d'infléchir une réflexion et des premiers outils prototype pour la construction et l'évaluation automatisé de modèle dans le cadre d'une utilisation collective. Si ce projet a permis de fonder la base d'une réflexion plus large qui nous motive encore aujourd'hui dans la présentation de ce projet, force est de constater que l'ampleur de la tâche une fois décrite rendait difficilement réalisable sa concrétisation en dehors d'une équipe pluri-disciplinaire, mobilisé sur plusieurs années sur ce sujet.

%Bharathy2010

\subsection{D'une démarche systématique à une démarche intégrée}


Deux niveaux de discussion doivent être envisagé, le modèle d'une part, et l'exploration de ce modèles d'autres part.

%Une réflexion en terme d'outils, une réflexion en terme de couplage entre les outils, une réflexion en terme de plateforme support garantissant une dimension collective à cette réflexion.

L'objectif est la mise en place d'un outil qui fait office d'attracteur,  capable d'intégrer des outils et des méthodes, mais aussi d'incubateur capable de catalyser un processus de standardisation des outils ou méthodes qui s'appuient dessus. 

L'intégration des méthodes permet d'envisager la construction d'une base de discussion

Celui ci au contraire ne peut que s'enrichir du fait des échanges qui se produisent à l'orée de chacune des disciplines, promesse ici d'une démarche compatible avec l'ouverture propre aux système complexe, souvent avancé mais encore difficile à concrétiser.
 
Les freins historiques à la diffusion de méthodologies et d'outils sur la validation que nous avons ainsi identifiés précédemment peuvent alors être intégré dans une vision plus élargie en accord avec les derniers prérequis technique et méthodologique qualificatif d'un travail dit scientifique

Nous pensons qu’une stratégie d’organisation de ce champ peut s’inspirer  de ce qui a été pratiqué au cours des années 1960 à 1980 par les mathématiciens et les informaticiens qui ont acculturé les sciences humaines et sociales aux pratiques de l'analyse des données, en développant des méthodes autour de logiciels d'accès facile et d'utilisation standardisé.
