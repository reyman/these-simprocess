
%PEU CLAIR : Second, model validation can be expected to vary according to the type of validity criteria used.C'est cette notion qui est appelés par Hermann dans le deuxième point de sa définition pour la validation, et dont on peut trouver ci dessous une expression qui établit le lien avec la problématique de la représentativité.


Comment qualifier alors la validité d'un modèle, et plus particulièrement les hypothèses que contient ce modèle ?

Hermann s'interroge à ce titre sur la nature et la crédibilité de la relation qui peut être tissé entre un système de référence (plus ou moins accessible) et les briques mobilisé dans le modèle lorsqu'il s'agit par exemple de développer avec un même modèle des scenario alternatifs tout aussi crédible les uns par rapport aux autres. Cette réflexion nous ouvre à une autre problématique, celle de l'équifinalité, et de la sous-détermination, deux notions qui semble par ailleur difficile à différencier, l'une venant de la biologie, et l'autre ayant été démocratisé par Quine.


%Après discussion avec Clémentine il y a aussi le fait que les critères ne sont pas forcément connus à l'avance, et viennent contraindre le modèle au fur et à mesure de sa construction.

\autocite{Cottineau2014a}

ont on ne peux savoir si elle est lié à un différentiel de niveau d'abstraction, à un défaut d'implémentation, à un défaut de paramétrage.

Il ne s'agit pas forcément ici de porter un jugement de valeur sur les hypothèses, ou sur la pertinence de leur mobilisation compte tenu de la question posés


Du point de vue du modélisateur, quels sont les incertitudes révélés dans l'activité de construction ? Et comment peut on jugé de la validité des hypothèses dans l'encadrement L'établissement de la valeur d'une hypothèses face à un ensemble de critère d'évaluations, mais également celle qui juge de l'évolution

--- \hl{en cours de construction} ---

Cette logique soulève au final plusieurs questions :
> Comment jauger la valeur d'une hypothèse ? Avec des indicateurs, oui mais quelles indicateurs ?
> Comment

% Critères agissent comme une contrainte sur le domaine de validité exprimé, et pousse dans un premier temps non pas tant le modélisateur vers un degré de réalisme plus important, mais vers la découverte de zones de comportements qui permettent le retravail des hypothèses


% Multiplication critères va de paire avec le scenario poursuivie par le modélisateur,
% De la valeur des hypothèses mises en jeu ? Equifinalité, exploration ?
% scenario : complexification, simplification ?

% A developper ou pas ?

%On retrouve ainsi de façon implicite à son argumentation l'expression de cette difficulté pour le modélisateur d'atteindre cette mise en relation du modèle opérationnel (plus ou moins simplifié fonction de l'objectif poursuivis) et d'une réalité au travers l'établissement de critères objectifs, réalité dont on sais par ailleurs qu'elle est déjà déformé à la fois par la vision localisé de l'expérimentateur sur un phénomène et par celle du choix de la mesure, de la structure mobilisé pour le capturer.


\hl{ avec retour à la neutralité car on propose des techniques, comme analyse de sensibilité, et on affirme la aussi la dépendance du modèle à l'objectif poursuivi, mais on ne sais toujours pas quel est la valeur des hypothèses ... une telle approche se rapproche de la conclusion qu'on a pu tenir au début du chapitre, il n'y a pas vraiment de manuel autre que des bons conseils, bref, ici aussi on botte en touche conscient des limitations de chacune des techniques. (permet d'apporter la question de la sous détermination gentiment, en la présentant comme une richesse en science humaine)}


IDEE : PASSAGE DE MULTI CRITERE ON SUIT ENSUTE LE PLAN POUR ALLER VERS LIMITATION IMPOSÉ PAR LA SOUS DETERMINATION, ET L'ARGUMENTATION DE SULLIVAN

\hl{------------------------ en cours ------------------------}




Appui sur l'importance du raisonnement dans la qualité de la validation, passage sur le collectif ?

Ici deux aspects important ne sont toujours pas traités, la construction du modèle comme processus historique lui aussi validable, la gestion de la sous détermination données / théories.

% Un constat effectif avec AMORAL + REMARQUE DE DENISE SUR FORRESTER
% + REPONSE A UN DES SEVEN SINS QUI ÉTAIT LE MODELE BLACKBOX

La naissance des systèmes dynamiques de Forrester allant de pair avec cette nouvelle méthode de construction des modèles autorisant la construction de structure causale beaucoup plus complexe que les précédentes techniques de simulation.

LeBerre1987 = Graphe causal ?

%Une critique qui tient à la structuration des modèles , notamment lorsqu'ils sont construit comme des systèmes faisant interagir des chaînes complexes de causalités, comme c'est le cas dans le cadre des systèmes dynamique ou des modèles multi-agents, dont le support conceptuel et formel est plutôt à trouver dans les outils du paradigme systémique.


=> Une des solutions on la vu poursuivis par les auteurs à été de se détacher de cette subjectivité sans toutefois la nier, en proposant une démarche théorique de construction de modèle qui délègue cette responsabilité au constructeur.

C'est du fait de cette contiguïté entre approche philosophique, et les approches pratiques de la validation qu'opèrent une relecture ou une appropriation des termes responsable de la plupart des ambiguïtés qui conduisent encore aujourd'hui à des débats terminologiques sans fin. \autocite{David2009}

Ces définitions apparaissent dans de nombreuses publications, toute disciplines confondues, y compris en géographie. Elles sont supposés offrir un cadre structurant et relativement neutre pour penser le processus de construction des modèles en général, et propose une terminologie suffisamment claire pour la mise en œuvre de pratiques standardisées.

Si l'approche plus récente de Sargent a certes permis de définir une démarche générique, elle exclue volontairement du débat le contexte subjectif de leur utilisation, et renvoie chaque discipline à l'explicitation de ses propres usages guidant l'avancement dans le processus incrémental de validation. \hl{Il en est de même pour la plupart des guides existant ...}

Mais cette approche de délégation, si elle a le mérite d'offrir un cadre structurant et neutre, qui est largement repris dans différentes disciplines, ne suffit pas. Car comme le disent bien ces auteurs, la validation est une étape incrémentale, qui s'effectue dès les premières itérations, ce qui renvoie dès les premiers instants le modélisateur à sa propre débrouillardise avec les outils, et laisse irrésolu tout les problème périphériques à cette mise en oeuvre... (cf faire plutot un rappel à la première partie sur la validation)


Dialogue avec les outils
Dialogue avec les chercheurs
Dialogue avec l'extérieur
?

Ainsi dans le cadre de notre étude, le terme \enquote{vérification}  \foreignquote{english}{[...] stands for absolute thruth }  \autocite{Oreskes1994} et se rapporte avant tout ici à la notion d'équifinalité \autocite{OSullivan2004} En dehors de toute considération technique, cette équifinalité qui décrit le fait que m-modèles créés par les scientifiques peuvent représenter la même réalité ( ou modèle de la réalité ), est tout à la fois un moteur et une limitation dans notre capacité de construction des connaissances.


\paragraph{La limitation des approche en ingénierie pour la validation en science sociale}

= Si depuis les auteurs comme Sargent et Balci ont largement revu leur cadre d'analyses afin d'y intégrer d'autres techniques de validation,

Toutefois, et c'est sûrement là le prix à payer d'une telle généricité dans les termes, cette définition ne prend pas en compte le contexte d'application où opère cette validation, vérification.

Si ce qui compte avant tout c'est le contenant du modèle, alors il faut prendre en compte plusieurs limitations. La pluri-formalisation des modèles, la multiplicité des niveaux de généralités.

L'incrémentalité de la démarche ? (présente dans les définitions, mais se rapporte à un catalogue de test, voilà tout.)

Sans se raccrocher non plus à l'étiquette de relativiste, qui nous obligerai à nous couper de tout discours scientifique, la position défendue par Naylor parait encore plus intenable pour une application dans les sciences humaines et sociales.

Quand à la vision poppérienne, qui assimilerai le processus de validation des modèles à une démarche de falsification, même si elle est intéressante, nous parait la aussi incompatible avec l'acceptation de la pluralité des points de vues qui fondent le débat dans les sciences humaines.


mais également de façon générale en sciences humaines et sociales, dont on a bien du mal à imaginer qu'elle supporte un tel transfert de ces concepts d’ingénierie sans aucune transformation, un point détaillé par la suite.




une notion difficile à saisir du fait de son rattachement à un débat philosophique, nécessaire dès lors qu'il s'agit d'évaluer la connaissance produite par les modèles.

Ce rapport entre

En effet, la question de la \enquote{Vérification} des modèles, au sens philosophique du terme (valeur de vérité), reste indépassable du fait des multiples biais amenant l'observateur à toujours questionner la valeur de cette connaissance qui résulte d'un transfert entre les résultats d'un modèle volontairement imparfait (\enquote{simplifié}, donc réducteur par définition), et la \enquote{réalité} dans toute sa complexité \autocite{OSullivan2004}.

%A REINTEGRER COMME PASSAGE POUR LEQUIFINALITÉ
L’existence de théories alternatives multiples est une constante dans l’histoire des sciences humaines. L'étude de l'objet social est un construit contextuel qui se nourrit d'une multiplicité des point de vues. C'est à ce titre que Jean-Claude Passeron \autocite{Passeron2006} nous met en garde contre une tentative de vérification des modèles qui serait décorrélée de tout contexte historique. Pour lui le faillibilisme poppérien qui se cache derrière la méthode hypothético déductive ne peut pas s'appliquer à la construction de théorie dans le cadre des sciences humaines et sociales. L'équifinalité est à ce titre un moteur permettant de confronter nos théories sur un objet social  qu'il est impossible de tout façon impossible de voir dans son unicité.

Le processus de modélisation apporte une dimension supplémentaire à l'analyse de chacun de ces points de vue.Car il est hélas impossible de prouver par les modèles qu'il n'y a pas un tout autre ensemble de fait stylisés ou d'interactions qui soit capable d'arriver à la même observation, enlevant de fait toute unicité d’une explication \enquote{scientifique} au point de vue représenté par le modèle. L'équifinalité est donc à ce titre une limitation indépassable à la connaissance qui peut être déduite de nos modèles.

espace paramètres !

Le terme \enquote{validation} quant à lui est souvent entendu pour définir un état qualifiant la correspondance entre des observations empiriques et les sorties de la simulation. Compte tenu de la notion d'équifinalité, cet état de correspondance ne suffit pas à prouver que le modèle représente bien la \enquote{réalité}, dans la mesure où l’unicité de cette adéquation peut être remise en cause par le jeu de nouvelles hypothèses.

\paragraph{Limitation ancienne}


De façon plus générique la percolation du concept d'auto-organisation dans les sciences sociales et en géographie permet il me semble de donner une définition plus générale de ce type de sous détermination comme résultat de l'étude d'un processus à l'équilibre (On parle ici d'équilibre d'état, mais éloigné de l'équilibre thermodynamique, dans un système ouvert, cf. \textit{steady state} de Prigogine) sachant que tout \textquote[Pouvreau2013, 114]{[...] processus d’équilibre peut être formulé téléologiquement [autrement dit] Toutes les lois systémiques ont la particularité que ce qui apparaît pour l’ensemble du système comme un processus causal d’équilibre peut être formulé téléologiquement pour les parties. Ce qui correspond à un processus causal d’équilibre apparaît pour la partie comme un événement téléologique, en ce que l’action de cette dernière semble dirigée vers le \enquote{but} consistant à prendre sa place \enquote{convenable} dans le tout}.

Peu importe donc l'étude de cette loi en tant que telle, puisque celle ci apparaît comme phénomène observable universel, ce qui intéresse le scientifique, ce sont les faisceaux d'hypothèses plausibles permettant d'approcher (ou pas, comme on l'oublie souvent, la négation est aussi explication !!) cette loi. La particularité de la géographie à ce niveau résidant avant tout dans sa capacité à maintenir ce faisceau d'hypothèse cohérent dans une diversités d'échelle et de temps, plus difficile à mobiliser dans d'autres disciplines.

Si on reprend l'objectif avancé par \autocite{Varenne2014}, \enquote{[...] la fécondité propre à la géographie de modélisation contemporaine et à ses différentes formes de manifestation tient en grande partie à sa capacité à affronter cette question de la sous-détermination, à comprendre qu’il ne s’agit plus tant pour elle de chercher des théories que de développer des modèles aux fonctions épistémiques multiples.} Si on comprend les enjeux d'un tel projet, se pose alors les moyens de sa réalisation; la systématisation des évaluations devient un outil au cœur de la construction des modèles, absolument nécessaire pour rendre cette fouille de modèles réaliste, et passé peut être à une échelle supérieure, celle de la construction et de l'étude de famille de modèles comme premier élément de réponse intégrateur de la pluralités des points de vues.

La notion de \enquote{laboratoire virtuel} traditionnellement limité à l'expérimentation du modèle mute, et se pare aujourd'hui d'une acception légèrement différente. Des chercheurs \autocite{Schmitt2014} \autocite{Amblard2003} ont voulu étendre cette notion pour y inclure également l'ensemble des méthodes et outils jugé nécessaire à l'étude de ce premier niveau d'expérimentation que représente la construction d'un modèle de simulation (la variation des hypothèses dans le modèle), désignant par ce fait un niveau supplémentaire d’expérimentation (la variation des outils et méthodes pour construire et étudier le modèle).

%\begin{quotation} In fact, utility of simulation is sometimes confused with validity. The one refers to its usefulness for some purposes, whereas the other refers to its degree of correspondence with the real world. Since utility requires some degree of validity, some authors speak of a model as having been \enquote{validated} by some use to which it has been put. Validity of a model, however, is not and end in itself but merely a means of enhancing the utility of the model – and usually only up to a point. Both validity and utility are commonly matters of degree. […] While validity is the ultimate test of a theory, the ultimate test of a model is its utility.  \\ \sourceatright{ \autocite{Guetzkow1972}}\end{quotation}

%Comme \autocite{Amblard2006} le propose, nous remplacerons donc le terme de \enquote{Validation}, qui prête à confusion, par celui d’\enquote{évaluation}, qui n'est pas sans rappeler la notion d'utilité telle que définie dans la citation ci dessus.

\paragraph{Quelle validité pour l'analogie du laboratoire ?}

%Raisonnement aussi important que le reste ...

Dans le cadre de cette thèse, nous défendrons une \enquote{évaluation} de modèle qui se confond presque complètement avec la méthodologie de construction qui la soutient. Cette \enquote{ validation interne } doit selon nous être systématisée au regard de la \enquote{ validation externe } qui mesure classiquement la correspondance entre données simulées et observées face à la question posée. C’est en cela que la démarche que nous proposons est \enquote{ systématique }. Les opérations nécessaires à la \enquote{ validation interne } telles que l'introduction, la modification, ou la suppression d'hypothèses, s’effectuent donc à la mesure de leur apport qualitatif et quantitatif dans l'explication de la dynamique globale sur laquelle se fonde la \enquote{ validation externe }. Autrement dit, c'est la recherche d'une cohérence qualitative autant que quantitative de la dynamique interne qui nous guide dans notre recherche de correspondance avec les données observées.


% Un point de vue partagé par {Batty2001} ce qui permettrai d'introduire la notion de système complexe également !

\subsubsection{Ouverture sur le collectif}

Ainsi plus que les solutions techniques, c'est dans le processus de discussion et d'échange autour des hypothèses admises dans les modèles que notre connaissance sur les phénomènes réels est amenée à progresser. Par la mobilisation, l'hybridation, la confrontation de modèles ou briques de modèle issues d'angles de vues inter-disciplinaires,  on met en œuvre une grande discussion à même d'éclairer cette dynamique globale qui serait de toute façon insaisissable dans sa globalité. {cf transcidisciplinarité de morin ?}

\autocite{Rouchier2013} s'appuyant sur une définition de \todo{Gilbert et Artweiler} décrit cette forme de validation basée sur la réutilisation et l'enrichissement collectif des modèles comme étant post-moderne, \enquote{ dans la mesure ou elle base la valeur d'un modèle au regard de son usage par une communauté d'usagers }. Il y a donc dans le processus d'évaluation des modèles de simulation une dimension collective qui ne peut plus être niés dans l'établissement d'outil et de méthodologie . De façon plus générale, \autocite{Rouchier2013} évoque et décrit bien dans un article récent \enquote{  Construire la discipline \enquote{ Simulation Agent }} la nature de ce mouvement structurant qui œuvre dans la construction de communauté scientifique. Celui ci prend forme autour de revues revendiquant une large ouverture inter-disciplinaire, tel que JASSS, qui font alors office de catalyseur en supportant, relayant ces discussions de fond, à la fois sur le plan méthodologique et technique.

Pour pousser l'analogie du \enquote{laboratoire virtuel} encore plus loin, il s'agirait alors d'ouvrir ce laboratoire aux autres scientifiques, d'en faire \enquote{place publique} afin de montrer l'histoire de nos protocoles, de nos modèles, de nos résultats \foreignquote{latin}{in vivo}, en assumant au passage toutes les contraintes que cela suppose. Dès lors, comment ne pas mettre en relation la complexification de cette représentation avec une épistémologie des pratiques du laboratoire tel que développés par Ian Hacking, ou Bruno Latour , et d'évaluer nos experimentation au regard d'un réseau de résultat cohérent, et non plus de théories dont on ne peut pas plus donner au final de réalité qu'à celle donnés à nos expérimentation ?

Si les débats sur le plan de l'analogie entre expérimentation réelles et virtuelles sont encores brûlant, un certain nombre de différence et de points communs ont déjà été assurés, et permettent de manipuler cette analogie avec prudence. Et nombreux sont les chercheurs ayant déjà suivis une voie similaire, replacant l'abduction et ses différents supports dans la construction et l'évaluation des modèles, et en acceptant au préalable les préceptes d'Epstein, dans son fameux if you didn't grow it you didn't explain it ... %% A developper.

Il s'agit maintenant d'explorer cette épistémologie qui remet au premier plan la démarche exploratoire et les outils qui la supportent, semblable en plusieurs points aux

Faisant cela, l'autonomie du modèle se diffuse à l'autonomie des démarches, des outils qui la composent, et des personnes qui les manipulent.

Une trajectoire des modèles déjà constaté dans nos pratiques de modélisation \autocite{Banos2013}, l'inter-disciplinarité inhérentes aux systèmes complexes cautionnant ces migrations pour éclairer des objets complexes à l'aube de cette diversité de points de vues, par l'emploi de nouvelle théories, de nouvelles échelles de temps et d'espace, et impliquant la transformation, au delà du modèle, de la démarche accompagnante qui permet son évaluation.

Quelques auteurs progressent sur cette voie en sciences humaines et sociales, mais cela reste des cas relativement isolés \autocite{Ngo2012} \autocite{Schmitt2014} \autocite{Heppenstall2007} \autocite{Stonedahl2011a} entre autres.

Dans sa conclusion \autocite{Rouchier2013} mise sur le développement de la crédibilité de cette discipline dans les années à venir, grâce aux revues, aux règles de conduites édictées, et aux modèles repris et discutés au cœur de cette communauté \autocite{Hales2003}.

%penser a faire un schema sous forme d'arbre a différentes racine, plutot vertical donc ....

%Au moins deux entrées epistémo pr repenser la pratique de l'évaluation :
%a) epistémo expérimenation interressante a aborder, car permet d'intégrer certains notions intéressante, comme l'autonomie des modeles, la reintroduction de l'experience face a la théorie, les style de pensée cumulatif qui rendent  compatible différente démarches, etc...
%b)la piste des mécanismes , avec filiation en biologie, refus de lhypthetico deuctivisme et l'absence de loi deductive, pont entamé par manzo, avec etude mot mécanisme qui peut etre prolongé par le papier quui différencie deux type demecanisme, et raccroche a la vision de la nouvelle biologie systémique en certain aspect ... introduire machamer et elseinbroch egalement ....
%=> Dimension collective supplémentaire a ces approches qui a elle seule ne font que définir une démarche de construction, qu'il faut rendre collective,  ce qui apporte contrainte supplémentaire ? (pas sur que ca soit au meme niveau en fait)


%Même si il est bon de garder une vision du futur optimiste du fait des avancés qui ont émergé des discussions ces dernières années, les problématiques que l'on rencontrent encore aujourd'hui dans le cadre de la simulation de modèles agents en géographie continue de faire écho à celles déjà mainte fois relayées par diverses publications ces dernières décennies\todo{ref JASS} \autocite{Squazzoni2010}  \autocite{Richiardi2006} \autocite{Windrum2007}. Sachant cela, il est difficile alors de ne pas sentir naître un sentiment plus mitigé sur cet avenir, car si la communauté n'arrive pas à dépasser tout ou partie des problèmes qui enrayent la diffusion des pratiques de simulation, comme cela semble être le cas, alors c'est toute la reconnaissance de ce champ comme une discipline scientifique à part entière qui reste limité.
