
\graphicspath{{Figure1/}}



\chapter*{Introduction}

\epigraph{Nous sommes comme un patient qui sort d'un coma aussi long que la vie d'une étoile.
Ce dont nous ne pouvons nous souvenir, nous devons le redécouvrir }{---  \textup{Robert Charles Wilson}  Axis}

La géographie est partie prenante des bouleversements considérables introduits par la numérisation dans l’ensemble des pratiques scientifiques depuis à peine deux décennies, et cela à plusieurs titres. Les manifestations les plus évidentes tiennent à la prolifération des informations individuelles " géolocalisées " désormais disponibles sur toutes sortes de support, et notamment, ce qui est entièrement nouveau, en situations de mobilité 	\todo{ (Fen-Chong, 2012) } (Fen-Chong, 2012).  Les dispositifs techniques de repérage comme le GPS et l’ouverture des systèmes d’information géographique à l’interactivité grâce à la version 2.0 d’Internet donnent lieu au développement d’une " géographie volontaire "\todo{ ( Goodchild, XXX, Openstreetmap…)}, qui conduit à diffuser auprès du grand public des pratiques et des savoir-faire jusqu’ici réservés aux professionnels. Le très grand nombre des institutions privées ou publiques qui partagent ce nouvel engouement pour l’inscription spatiale de leurs activités, tout comme la croissance fabuleuse des " réseaux sociaux " sur Internet  contribuent à l’immense développement de ce qu’il est convenu d’appeler, sans traduction en français, les " big data " \todo{ (ref dossier special Nature ? )}. Ces masses de données très labiles, évoluant souvent en temps réel, qu’il est relativement facile de collecter à différents niveaux d’agrégation, posent de nouveaux défis aux géographes en termes de traitement des ces informations, tout autant qualitatives que quantitatives. Les méthodes classiques de résumé des connaissances par la modélisation et la visualisation doivent être considérablement transformées pour s’adapter à cette nouvelle donne. 

Heureusement les capacités de calcul informatique et les méthodes de modélisation multi-échelles des informations spatio-temporelles se sont bien développées, en parallèle et en réponse à ces nouveaux défis. Parmi les sciences humaines et sociales, les géographes sont particulièrement présents dans l’expérimentation et la mise au point méthodologique, qu’il s’agisse des les appliquer à des données environnementales (Kanevski, Delahaye, Douvinet) ou à des problèmes de géographie urbaine (Batty, Banos, …Ruas) ou régionale (Wilson, Dauphiné, White, Engelen, Daudé) ou encore à l’analyse de réseaux (Rozenblat). 

Le laboratoire Géographie-cités a été pionnier dans l’application à la géographie des systèmes multi-agents, notamment avec la série des modèles Simpop réalisés en collaboration avec des informaticiens (Bura et al., 1996, Sanders et al., 2007, Pumain, 2012) mais aussi avec des modèles d’agents développés directement avec des logiciels simplifiés comme Netlogo (Banos…). L’évolution des modèles ne se limite pas à l’emploi de logiciels mais participe plus généralement des réflexions de la communauté scientifique intéressée par les systèmes complexes. Le GDRE S4 (Simulation Spatiale pour les Sciences Sociales) a par exemple inscrit son action parmi les premiers projets de l’Institut des Systèmes Complexes de Paris-Ile-de-France (ISC-PIF) fondé par Paul Bourgine \todo{ (ref) }. L’UMR  Géographie-cités est devenue en 2011 l’antenne  de l’Institut des systèmes complexes à l’Université Paris I et acquiert du matériel pour sa propre autonomie de fonctionnement.

Les systèmes complexes sont bien entendu au cœur des interrogations en sciences humaines et sociales, dans la mesure où il est connu depuis très longtemps dans ces disciplines que les interactions en jeu ne sont pas linéaires \todo{ (Morin, 200 ) }  (Morin, 200 ), que des individus engagés dans des processus collectifs sont susceptibles de donner lieu à des phénomènes originaux à l’échelon macroscopique (Schelling, 1978) \todo{ (Schelling, 1978) }, et que les situations initiales ou les effets de contexte sont parfois aussi déterminants que les modalités qui règlent les échanges entre les individus, suscitant des évolutions où la " path dependence " \todo{ (Arthur, 1994) } (Arthur, 1994) ou "enchaînement historique " joue un rôle très important, en limitant les expressions des dynamiques possibles.

Les modèles d’agents employés en géographie ont la particularité d’avoir été développés non seulement pour des simulations d’agents individuels, par exemple pour simuler la diffusion d’épidémies dans un territoire urbain ou régional ou sur un réseau (Banos SRAS, Badariotti, Laperrière, Eubank…) ou la diffusion d’innovations (Daudé), la propagation d’incendies (Langlois), ou encore pour éclairer les choix résidentiels (Bonnefoy…) mais ont démontré l’intérêt de modélisations fondées sur des entités plus vastes (villes, régions, voire états du monde) pour examiner les possibilités d’émergence à partir de leurs interactions à des niveaux géographiques plus larges. 

% % ----

La création de simulation de modèle, et d'une construction théorique capable d'intégrer la complexité des systèmes urbains va de paire avec l'introduction 1) du temps 2) de niveau individuel comme facteur explicatif. On peux observer ce changement selon deux points d'entrée 

L'implémentation des modèles d'Hagerstrand par Marble et Pits (Hagerstrand I et Hagerstrand II) 
 
En 1965 Peter Hagget cite le modèle de Morril La simulation semble toutefois se borner principalement à l'utilisation de Monte-Carlo et aux méthodes de la théories des jeux en 1965. 

Note p31 de Gould 2004 : "Mais il faut bien se rendre compte que la formulation de questions et les avancées méthodologiques sont les deux faces d'une meme piece" -> les nouvelle approches ouvrent de nouvelles voies à la pensée et au questionnement littéralement impensables auparavent, on peut citer par exemple la programmation déjàlinéaire, qui souleve (cf Leslie Curry, aussi cité ailleur par Hagget je crois) + introduction de Gould1970 "The intellectual revolution in geography since the middle and late fifties rests upon two main supporting pillars"

% PLUSIEURS points développement méthodologiques accompagnant renouvellement théoriques accompagnant nouvelle géographie : Hagerstrand , Orcutt -> causalité + individualisme méthodologique,  Forrester -> complexité
% + Prise en compte temporelle comme en parle Batty (a verifier)? 
% Hagerstrand premiere utilisation montecarlo en science sociale, vient a Washington et rencontre Morril... qui pour Benko Stromayer marque troisieme theme dominant le bouleversement quantitatif) Gould2004

% simulation permet de développer cette causalité ...
% Systeme dynamique, non linéarité, permet avancée fondamentale dans les questionnements, révélateur aussi de l'apport des techniques / méthodologies...
% Basculement vers explicatif !


Faire remonter texte sur la new geo Haggerstrand, individualisme methodologique, etc ici.

\subsubsection{Les facteurs déclencheur dans la crise de confiance dans les années 1970}
% Pour la geographie cela se cristalise autour des modèles de la RAND, mais la ou dans les autres disciplines, la simulation est mises en sourdines, en géographie elle continue de s'etendre ...
% Résumé des limites, écho avec les problématiques agents, et ouverture sur problématique de la validation en général, hors méthodologie => batty !
% La recherche en urban modelling presque exclusivement faite dans le cadre planning : p8 Batty1976
% Géographies s'en sort bien entre autre par introduction statistiques et modélisation de facon tres forte dans la discipline : Whitehand 1970 dans Johnston 2006)

Si il existe peu de témoignage faisant état d'une crise de confiance généralisé dans les sciences sociales dans les années 1970,  plusieurs auteurs font état les décennies suivantes de ralentissement constatés dans la mise en œuvre de simulations dans leur disciplines. % Est ce que l'on fait apparaitre l'enjeu dès le départ ? => La plupart du temps, ces papiers méthodologique pointent des arguments faisant état des limitations techniques, mais il apparaît de façon assez nette que la problématique de la validation des simulations et la lutte régulière pour reconnaître le caractère « scientifique » de la simulation et son intérêt pour dégager de la connaissance semble être un argument transerval dans les différentes disciplines et dans le temps.

Parmis les rares travaux sur le sujet, on trouve Starbuck et son équipe en 1971 {Starbuck1971} puis le retour sur cette étude constatant le ralentissement en 1983. L'équipe de Starbuck réalise en 1971 une étude inédite, avec pour objectif d'éplucher de façon exhaustive la littérature prenant pour propos la simulation. Au final nous dira l'auteur, l'exhaustivité ne sera pas atteinte, mais plus de 12000 publications en anglais pouront être classé, et plus de 2000 papier seront identifié sur la simulation spécifique en « Human Behavior ».

Si ce ralentissement dans la publication de simulations n'est pas forcément observables en 1969, date qui marque l'arrêt de l'étude (Starbuck met l'effet de tassement des publications sur les trois dernieres années sur le compte du nombre croissant de publications, impossibles à comptabiliser), Starbuck après un nouvel épluchage en 1983 des différentes revues majeures dans sa disciplines laquelle ??? constate la quasi-absence de nouvelles publications sur le sujet, voir pire, la remise au goût du jour de modèles de plus de 20 ans !

Mais cette surprise n'a finalement rien d'étonnant lorsque l'on observe, dans l'étude de Starbuck en 1971, qu'un peu moins de la moitié des publications ne proposait aucun modèle implémenté, la plupart des études se bornant à une discussion méthodologique.

Pour appuyer et résumer ce constat terrible, Starbuck cite John McLeod qui travaille depuis plusieurs décenies dans un des deux journals exlusivement orienté simulation (« Simulation » créé en , et « Simulation and gaming » en 1970): 

« According to  John McLeod who has been involved with Simulation magazine for two decades, one primary reason for the methodology's sorry state is that simulators have overstated its capabilities and so, subsequently, disapointed their audiences. »

Nous allons voir que cette citation illustre un constat que l'on peut retrouvé sous différentes formes dans bien d'autres disciplines.

Autre manifeste, et même constat affiché par Ostrom en psychologie sociale. Ostrom {Ostrom1988}, lorsqu'il revendique en 1988 l'importance de la simulation comme un « third way system » pour faire de la science,  fait également un constat assez accablant sur la place aujourd'hui tenu par cette pratique de modélisation dans le courant mainstream de la psychologie. Ainsi dit il,  force est de constater en 1988 le peu de retours rapportés par la discipline à ces différents manifestes : « Despite the clear relevance of these models to  social psychology, the simulation approach had not  caught the imagination of main stream social psychologists. Very few simulations had appeared in the core journals of the field prior to the publication of Abelson's chapter. […] At the time of Abelson's writing, simulation models had not made much contact with the dominant empirical pursuits of the field. »{Ostrom 1988, p382}

En archéologie également, ou de multiples auteurs font figure de pionnier dans la description de modèles, avec la publication de plusieurs articles fondateurs {Clarke1968} {Doran1970} dans une période marqué par l'arrivée massive des outils statistique dans les pratiques de la discipline qui marque la aussi une certaine rupture avec les pratiques de l'époques.

«  During the 1980s, relatively few archaeologists continued to advocate whole-society modeling, the most prominent of them being James Doran, who has called for the "formal modeling" of societies, especially the inter- action of their political and sociological subsystems. While much of Doran's work has been widely cited within the rela- tively small community of mathematically inclined archaeologists, his work has had relatively little influence beyond this small circle»{Aldenderfer1998}


Autre témoignage plus ancien d'un Anthropologue {Dyke1981}, et déjà la même conclusion se dessine : 

« The first use of computer simulation in anthropology appears to have been the work of Kunstadter et al in 1963. Since that time there has been a considerable increase in the number of publications whose results have depended on simulation studies. Despite this increase, it is probably fair to say that simulation has received at best only a cautious acceptance in anthropology. »

« The initial enthusiasm for a newly acquired ability to model complex systems, characteristic of the early days of anthropological simulation, more often than not led to an exaggeration of the capabilities and usefulness of computer models. In retrospect it seems clear that much of this excess could have been avoided had more attention been paid to testing (particularly to validation). The literature of the past 4 or 5 years, however, gives ample evidence that the situation has changed. Those who continue to use simulation seem to have paid much more attention to the problem of validation and tend to be more modest in their claims of utility. »

Le cas de l'archéologie est révélateur de cette tendance. Il semblerait que la pratique de la simulation en science sociale (sauf peut être le cas spécifique de la géographie) se concentre finalement dans de petites communautées de chercheurs, disposant de fortes compétences techniques initiales, qui vont continuer à travailler, à proposer des modèles, et à acquérir de nouvelle techniques et méthodologies en parallèle d'un courant « mainstream » intégrant seulement les nouvelles capacités offertes par les ordinateurs mais délaissant l'aspect simulation. Certains de ces chercheurs, comme par exemple Jim Doran, refont surface quelques années plus tard pour porter une nouvelle vague d'innovation lié à l'avénement de l'intelligence distribué, une technologie plus en correspondance on verra avec la vision de la simulation tel que certains chercheur l'avait déjà imaginé en 1970 {Doran1970}

=> Validation comme nouvel enjeu ?

\subsubsection{Changement de paradigme et renouveau dans la construction des simulations en géographie }

=> Introduction aux système complexes ... cf article Denise P
=> Construction des simulations, et question de leur évaluation devient une problématique centrale ...
=> N'a de cesse encore aujourd'hui de poser les même questions, et cela même si les techniques ont pu évolués (agent a permis d'aller plus loin dans la flexibilité, mais il n'a pas résolu la problématique de la validation, au contraire, en démocratisant il a probablement fait resurgir les aspects non controlés et néfaste .. ) 

=> cf Pourquoi encore aujourd'hui questions soulevés par bien detracteurs font écho comme autrefois à la scientificité de la méthode simulation / d'autant plus lorsqu'elle est agent ? 

\subsection{Comment construire des modèles de systèmes complexes qui participe à la production de connaissance}

En effet, la question de la " Vérification " des modèles, au sens philosophique du terme (valeur de vérité), reste indépassable du fait des multiples biais amenant l'observateur à toujours questionner la valeur de cette connaissance qui résulte d'un transfert entre les résultats d'un modèle volontairement imparfait (" simplifié ", donc réducteur par définition), et la " réalité " dans toute sa complexité  \autocite{OSullivan2004}.  Les termes " vérification " et  " validation " sont couramment rencontrés dans notre discipline, mais sous des acceptions différentes tenant souvent au transfert des terminologies entre ingénierie \autocite{Sargent1984} d\autocite{Balci1998}  et philosophie, ce qui conduit à  des débats terminologiques sans fin \autocite{David2009}. 

Ainsi dans le cadre de notre étude, le terme " vérification "  \enquote{[...] stands for absolute thruth } \autocite{David2009} \autocite{Oreskes1994} et se rapporte avant tout ici à la notion d'équifinalité \autocite{OSullivan2004} En dehors de toute considération technique, cette équifinalité qui décrit le fait que m-modèles créés par les scientifiques peuvent représenter la même réalité ( ou modèle de la réalité ), est tout à la fois un moteur et une limitation dans notre capacité de construction des connaissances. 

L’existence de théories alternatives multiples est une constante dans l’histoire des sciences humaines. L'étude de l'objet social est un construit contextuel qui se nourrit d'une multiplicité des point de vues. C'est à ce titre que Jean-Claude Passeron \autocite{Passeron2006} nous met en garde contre une tentative de vérification des modèles qui serait décorrélée de tout contexte historique. Pour lui le faillibilisme poppérien qui se cache derrière la méthode hypothético déductive ne peut pas s'appliquer à la construction de théorie dans le cadre des sciences humaines et sociales. L'équifinalité est à ce titre un moteur permettant de confronter nos théories sur un objet social  qu'il est impossible de tout façon impossible de voir dans son unicité. A ce titre, " les questions pour  la validation des modèles ne devraient jamais être abordées en dehors des questions relatives à leurs usages " \todo{Amblard}(Amblard)

Le processus de modélisation apporte une dimension supplémentaire à l'analyse de chacun de ces points de vue. Car  il est hélas  impossible de prouver par les modèles qu'il n'y a pas un tout autre ensemble de fait stylisés ou d'interactions qui soit capable d'arriver à la même observation, enlevant de fait toute unicité d’une explication " scientifique " au point de vue représenté par le modèle. L'équifinalité est donc à ce titre une limitation indépassable à la connaissance qui peut être déduite de nos modèles.

Le terme " validation " quant à lui est souvent entendu pour définir un état qualifiant la correspondance entre des observations empiriques et les sorties de la simulation. Compte tenu de la notion d'équifinalité, cet état de correspondance ne suffit pas à prouver que le modèle représente bien la " réalité ", dans la mesure où l’unicité de  cette adéquation peut être remise en cause par le jeu de nouvelles hypothèses.

\begin{quotation} In fact, utility of simulation is sometimes confused with validity. The one refers to its usefulness for some purposes, whereas the other refers to its degree of correspondence with the real world. Since utility requires some degree of validity, some authors speak of a model as having been « validated » by some use to which it has been put. Validity of a model, however, is not and end in itself but merely a means of enhancing the utility of the model – and usually only up to a point. Both validity and utility are commonly matters of degree. […] While validity is the ultimate test of a theory, the ultimate test of a model is its utility.  \\ \sourceatright{ \autocite{Schultz1972}}\end{quotation}

Comme \todo{cite{Amblard200x}} le propose, nous remplacerons donc le terme de " validation ", qui prête à confusion,  par celui d’ " évaluation ", qui n'est pas sans rappeler la notion d'utilité telle que définie dans la citation ci dessus.

\subsubsection{Une démarche pour systématiser l'évaluation des modèles}

Dans le cadre de cette thèse, nous défendrons une « évaluation » de modèle qui se confond presque complètement avec la méthodologie de construction qui la soutient. Cette « validation interne » doit selon nous être systématisée au regard de la « validation externe » qui mesure classiquement la correspondance entre données simulées et observées face à la question posée. C’est en cela que la démarche que nous proposons est « systématique ». Les opérations nécessaires à la « validation interne » telles que l'introduction, la modification, ou la suppression d'hypothèses, s’effectuent donc à la mesure de leur apport qualitatif et quantitatif dans l'explication de la dynamique globale sur laquelle se fonde la « validation externe ». Autrement dit, c'est la recherche d'une cohérence qualitative autant que quantitative de la dynamique interne qui nous guide dans notre recherche de correspondance avec les données observées.

A ce titre, le recours au calibrage, et la recherche de cohérence interne dans les dynamiques pourraient passer pour une tentative de mieux définir par ce biais les processus en jeu dans un contexte réel. Pour \autocite{OSullivan2004} cet argument est encore un leurre, car toujours au vu de l'équifinalité, si ces procédures améliorent bien la connaissance du modèle, absolument aucune garantie ne peut être donnée sur la qualité et la transférabilité de cette connaissance pour l'étude de processus réel. Cela est d'autant plus vrai lorsqu'il s'agit de système complexes, dont la nature même empêche toute  mesure des dynamiques à l'oeuvre lors des processus d'émergence, et rend donc discutable toute comparaison possible avec des dynamiques simulées. 

\begin{quotation} It is clear that assessment of the accuracy of a model as a representation must rest on argument about how competing theories are represented in its workings, with calibration and fitting procedures acting as a check on reasoning. So, while we must surely question the adequacy of a model that is incapable of generating results resembling observational data, we can only make broad comparisons between competing models that each provide ‘reasonable’ fits to observations. Furthermore, critical argument and engagement with underlying theories about the processes represented in models is essential: no purely technical procedure can do better than this.  \\ \sourceatright{ \autocite{OSullivan2004}} \end{quotation}

% Un point de vue partagé par {Batty2001} ce qui permettrai d'introduire la notion de système complexe également !

Ainsi plus que les solutions techniques, c'est dans le processus de discussion et d'échange autour des hypothèses admises dans les modèles que notre connaissance sur les phénomènes réels est amenée à progresser. Par la mobilisation, l'hybridation, la confrontation de modèles ou briques de modèle issues d'angles de vues inter-disciplinaires,  on met en œuvre une grande discussion à même d'éclairer cette dynamique globale qui serait de toute façon insaisissable dans sa globalité. {cf transcidisciplinarité de morin ?}

 \autocite{Rouchier2013} s'appuyant sur une définition de \todo{Gilbert et Artweiler} décrit cette forme de validation basée sur la réutilisation et l'enrichissement collectif des modèles comme étant post-moderne, \endquote{ dans la mesure ou elle base la valeur d'un modèle au regard de son usage par une communauté d'usagers }. Il y a donc dans le processus d'évaluation des modèles de simulation une dimension collective qui ne peut plus être niés dans l'établissement d'outil et de méthodologie . De façon plus générale, \autocite{Rouchier2013} évoque et décrit bien dans un article récent «  Construire la discipline « Simulation Agent » » la nature de ce mouvement structurant qui oeuvre dans la construction de communauté scientifique. Celui ci prend forme autour de revues revendiquant une large ouverture inter-disciplinaire, tel que JASSS, qui font alors office de catalyseur en supportant, relayant ces discussions de fond, à la fois sur le plan méthodologique et technique.

Dans sa conclusion \autocite{Rouchier2013} mise sur le développement de la crédibilité de cette discipline dans les années à venir, grâce aux revues, aux règles de conduites edictées, et aux modèles repris et discutés au coeur de cette communauté \autocite{Hales2003}. Même si il est bon de garder une vision du futur optimiste du fait des avancés qui ont émergé des discussions ces dernières années, les problématiques que l'on rencontrent encore aujourd'hui dans le cadre de la simulation de modèles agents en géographie continue de faire écho à celles déjà mainte fois relayées par diverses publications ces dernières décennies\todo{ref JASS} \autocite{Squazzoni2010}  \autocite{Richiardi2006} \autocite{Windrum2007}. Sachant cela, il est difficile alors de ne pas sentir naître un sentiment plus mitigé sur cet avenir, car si la communauté n'arrive pas à dépasser tout ou partie des problèmes qui enrayent la diffusion des pratiques de simulation, comme cela semble être le cas, alors c'est toute la reconnaissance de ce champ comme une discipline scientifique à part entière qui reste limité.

Et sur ce point, un regard sur l'histoire passée de la simulation dans les sciences sociales n'est pas fait pour nous rassurer, la plupart des problèmes cités comme facteurs limitants dès les années 1970 recoupent encore aujourd'hui tout ou partie de nos problèmes actuels. En forte interaction, ceux ci peuvent être rapportés à au moins trois dimensions explicatives, une dimension technique, une dimension méthodologique et une dimension institutionelle, ce qui peut être explique pourquoi ceux ci n'ont jamais pu être totalement résolus dans le cadre d'une seule politique, d'une seule projet, ou d'une seule publication : faible nombre de modèles publiés et reproductibles, absence de publication décrivant des protocoles d'évaluation de modèles et des mises en application de ces protocoles, difficulté d'accès à l'information et à la ressource technique nécessaire pour l'exploration des modèles, stratégie de publication misant sur la publication de modèles déjà finalisés mais jamais appliqués de nouveau, manque de formations adaptées ou dédiées, confrontation avec des courants disciplinaires " mainstream " ignorant l'activité modélisante, etc.

Dans notre volonté de proposer une démarche systématisant la construction et l'évaluation des modèles, ce contexte historique déceptif doit être pris en compte, et il nous faut prendre le partie que ce n'est pas la proposition d'une n-ième méthodologie à vocation englobante, universalisante qui sera capable à elle seule de lever ces barrières, et cela même si elle prend acte de cette dimension collective dans sa formulation (reproductibilité des modèles, des expérimentations).

 A ce sujet, il existe une histoire drôle chez les informaticiens, qui peuvent être régulièrement confronté à des états de l'art comportant pléthore d'approches (méthodologique ou technique) pour la résolution d'un même problème. Ainsi l'informaticien zélé, acteur de notre histoire, allume son ordinateur en arrivant dans son laboratoire et part à la recherche d'une solution pour son problème du moment. Mécontent de ne pas trouver un outil satisfaisant pour son problème à la fin de sa journée, celui ci se dit alors dans un éclair de lucidité " Tentons de créer une nouvelle méthodologie pour unifier toute ces approches hétérogènes en une seule !". Ce n'est que quelques mois plus tard, et au terme d'un développement difficile mais enrichissant, que la solution prend finalement forme. A ce moment là, force est de constater que ce ne sont plus 14 mais 15 solutions concurrentes qui s'affronte alors sur le marché des méthodologies pour la résolution de ce problème. Moralité ? Projeter la construction d'une n-ème méthodologie dans une volonté unificatrice (et donc forcément réductrice) peut certes être un exercice constructif (le protocole ODD qui tente d'unifier la description des modèles est en ce sens une expérience intéressante), mais force est de constater que celui ci a peu de chance d'enclencher le processus de standardisation tant attendu, d'autant plus lorsque cet effort s'exerce dans un cadre largement inter-disciplinaire dont les frontières tant sur les aspects méthodologiques que techniques ne peuvent pas être imaginé/intégré par une seule et même personne.

Sur ce dernier point, une première réflexion révélatrice de cette expérience a ainsi été mené par Thomas Louail et Sébastien Rey au laboratoire Géographie-Cités en 2010 (?). L'objectif de ce travail était de lever les limites des méthodologies et outils existants autour des modèles de la famille de modèle Simpop2 afin d'infléchir une réflexion et des premiers outils prototype pour la construction et l'évaluation automatisé de modèle dans le cadre d'une utilisation collective. Si ce projet a permis de fonder la base d'une réflexion plus large qui nous motive encore aujourd'hui dans la présentation de ce projet, force est de constater que l'ampleur de la tâche une fois décrite rendait difficilement réalisable sa concrétisation en dehors d'une équipe pluri-disciplinaire, mobilisé sur plusieurs années sur ce sujet.

Bharathy2010

\subsubsection{D'une démarche systématique à une démarche intégrée}

Cette réflexion menant à la construction d'une démarche systématique pour l'évaluation et la construction de modèle de simulation doit certes être mené dans le cadre d'une amélioration de nos pratiques, mais nous avons vu que cet effort n'avait pas pour vocation première l'établissement d'un standard. En effet, la diversité de ces même pratiques rend impossible et réducteur une telle approche. 
Un autre point de vue défendu ici, montre qu'il est plus intéressant de retranscrire cette diversité par un ensembles de couplage entre des outils conçu sur une base autonome et standard;

Autrement dit, ce projet s'inscrit dans un objectif double, il s'agit à la fois de garantir l'indépendance et la réutilisation des outils dans de multiples configurations tout en problématisant leur utilisation dans des constructions méthodologique (ou cas d'utilisation) que nous jugeont pertinent pour l'exploration et la construction de modèles en géographie. De ce fait ils participent à la création d'un écosystème appropriable par tout les points de vues, non réducteur car flexible dans le cadre de nos pratiques, et appuyant en plusieurs points cette dimension collective pour la construction et l'évaluation de modèle.

Deux niveaux de discussion doivent être envisagé, le modèle d'une part, et l'exploration de ce modèles d'autres part.

Une réflexion en terme d'outils, une réflexion en terme de couplage entre les outils, une réflexion en terme de plateforme support garantissant une dimension collective à cette réflexion.

L'objectif est la mise en place d'un outil qui fait office d'attracteur,  capable d'intégrer des outils et des méthodes, mais aussi d'incubateur capable de catalyser un processus de standardisation des outils ou méthodes qui s'appuient dessus. 

L'intégration des méthodes permet d'envisager la construction d'une base de discussion

 Celui ci au contraire ne peut que s'enrichir du fait des échanges qui se produisent à l'orée de chacune des disciplines, promesse ici d'une démarche compatible avec l'ouverture propre aux "système complexe", souvent avancé mais encore difficile à concrétiser.
 
 Les freins historiques à la diffusion de méthodologies et d'outils sur la validation que nous avons ainsi identifiés précédemment peuvent alors être intégré dans une vision plus élargie en accord avec les derniers prérequis technique et méthodologique qualificatif d'un travail dit "scientifique"  

Nous pensons qu’une stratégie d’organisation de ce champ peut s’inspirer  de ce qui a été pratiqué au cours des années 1960 à 1980 par les mathématiciens et les informaticiens qui ont acculturé les sciences humaines et sociales aux pratiques de l'analyse des données, en développant des méthodes autour de logiciels d'accès facile et d'utilisation standardisé.

\subsubsection{Un exemple historique pour l’émergence de méthodes standardisées}

Il n’est pas nécessaire de remonter très loin dans l’histoire de notre discipline, pour découvrir comment ont pu émerger, à partir  de pratiques localisées, des outils et des méthodes qui sont aujourd'hui largement diffusés et considérés comme acquis et standardisés. Ainsi, bien qu’il fasse partie de notre outillage de « tous les jours » pour analyser des données multi-dimensionnelles, le terme ACP (Analyse en Composantes Principales) n'apparaît concrètement qu'à l'automne 1962 ( selon Benzécri 1977  p9, lors d'une conférence au Collège de France). 

Quelques indications de Jean-Paul Benzécri (Benzécri 1977) sont particulièrement éclairantes à cet égard lorsqu'il relate la publication fondatrice en 1973 de son ouvrage « l'analyse des données » 

a)  plus de 70 auteurs ont participé aux tomes I et II et la construction des méthodes s'est faite par confrontation avec les écoles internationales existantes (pxx) ; Michel Armatte (Armatte 2008) soulignera dans le préambule de l'analyse rétrospective de ce livre à quel point ces techniques alors innovantes ont pu susciter l'engouement tout autant que le rejet de la part de la communauté statistique.

 b)  les quelque douze chapitres que comporte ce livre sont largement issus et enrichis d'un travail autour de données et de chercheurs de toutes disciplines ; ainsi « le codage, la critique et l'interprétation des résultats s'étant perfectionnés au fur et à mesure que se diversifiaient les données » (p28) 

Si ces deux points relèvent bien l'importance de l'aspect interdisciplinaire dans la construction des méthodes en Analyse de données, un autre récit de Ludovic Lebart (Lebart 2008) souligne l'importance de la mise à disposition des connaissances dans des manuels pour promouvoir leur diffusion. Ainsi Jean-Pierre Fénélon et Ludovic Lebart, « deux timides et  maladroits apôtres de Jean-Paul Benzécri » sont convaincus lors de la publication de leur livre « Statistique et Informatique Appliquées » d'être en 1970  les pionniers d'une « révolution censée embraser toute la science statistique ». Dans la droite ligne de leur précurseur, qui avait déjà mis à disposition dans son livre « Analyse de Données » un programme en FORTRAN (pour les heureux possesseurs d'un 1620 IBM !), Ludovic et son acolyte proposent eux aussi les codes sources et des méthodes des programmes. Ils cristallisent ainsi des pratiques, qui à une époque ou l'omniprésence des « MainFrame » et la quasi absence de système d'exploitation pour l’exécution de programmes compilés (donc échangeables) contraint à la libre diffusion des codes sources entre les équipes. Loin de s’arrêter là, cette équipe fonde l'ADDAD (Association pour la Diffusion et le Développement de l'analyse des données) et publiera une revue qui fait la promotion de ces pratiques jusqu'en 1997. Cet esprit perdure encore dans une revue fondée en 1988 par des disciples statisticiens, celle ci est toujours publiée au format électronique sous le nom de  MODULAD. 

De par ces deux mécanismes agissant de concert, construction inter-disciplinaire et libre diffusion des méthodes via des manuels fondateurs, les techniques d'Analyse de Données percolent rapidement dans les publications en géographie française dès les années 1970 (Beguin 1979, vous pouvez citer mon article de 1976 dans l’Espace Géographique et celui écrit avec Madeleine Brocard et Violette Rey en 1973, et puis aussi le manuel Chadule autre ref fondatrice en fr ?) avec l'aide de cette poussée révolutionnaire venant de la géographie anglo-saxonne, et la traversée de leurs idées largement favorable à ces outils ( en témoigne la traduction française de l'article l’ouvrage  de Peter Haggett (1967) en 1973 par Hubert Fréchou sous l’impulsion de Philippe Pinchemel). La multiplication des publications bravant, décortiquant, adaptant les nouvelles méthodes génère vite des discussions et des améliorations autour de ces nouveaux outils et de la manière de les utiliser dans ce qui laisse très vite préfigurer les méthodes de la géographie quantitative moderne.

Ainsi si l'apport inter-disciplinaire a été un moteur très fort dans la construction des outils en Analyse de données, il a également très largement participé à sa diffusion par le biais de la ré-appropriation des méthodes et outils par les communautés.

Si le contexte est aujourd'hui bien différent, les vecteurs principaux de communication dans la recherche ayant muté pour s'adapter à la révolution Internet, de nouveaux outils et plateformes apparaissent tous les jours sur Internet pour compléter une offre existante déjà extrêmement riche.


Les objectifs pour cette thèse

Voir en, quoi on peut faire évoluer les pratiques pour systématiser l’évaluation dans les modèles d’agents

Revue des pratiques existantes (chapitre 1)

Les fonctionnalités d’un laboratoire virtuel étendu (construction des modèles, exploration, visualisation) (chap 2)

Démonstration de l’intérêt pour le calibrage (chapitre 3)

Réalisation d’analyses de sensibilité (chapitre 4)

Conclusion



\listoftodos


