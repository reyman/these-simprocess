

- La question des modalités opérantes derrière la mobilisation des hypothèses et des critères au travers de ce jeu abductif pour la connaissances, 

- également cette activité de \enquote{facilitation} intervenant dans la transformation et l'articulation des hypothèses prédisposé à rentrer dans ce jeu. 

Tout ces éléments renvoie à l'existence d'un contexte et d'une dimension temporelle qui s'étend au delà de cette logique de preuve.
 - construction des indicateurs devient aussi importantes
 - raisonnement n'est fiable que si il est construit sur la base d'un rapprochement sain
 -



TEMPOREL 

- Aller retour entre construction - exploration 
- probleme de la durée de vie des hypothèses vis à vis de l'évaluation, besse 2000 = prise en compte du contexte global
- Facilitation ? Reste donc à explorer comment cette \enquote{facilitation} s'exprime au travers de la construction du modèle de simulation. 

CONTEXTE


- Construction des critères

L'activité de construction et de mobilisation des critères permettant de questionner le modèle lors de sa construction révèle en réalité une autre activité de modélisation, aussi questionnante et importante que la construction en elle-même du modèle de simulation. 

Replacer dans une dynamique de construction, les deux activités pourrait même apparaitre comme indissociable, la complexification des modèles apellant fort probablement l'introduction toujours plus grande de critères pour en mesurer la cohérence interne.

Or si il est courant d'établir un modèle conceptuel pour cristaliser un jeu d'hypothèse à mobiliser dans une simulation, la plannification des critères pour mesurer l'impact réel de ces hypothèses dans la dynamique du modèle est moins courante, et pourtant celle-ci semble tout autant nécessaire. Il faut dire aussi que ceux-ci, tout comme les mécanismes ajoutés, ne sont pas toujours connus par avance, et oblige là encore à voir l'activité de modélisation comme une activité de raisonnement qui mérite toute sa place dans les publications. L'histoire ayant mené à la construction d'un modèle et des critères qui l'acccompagne devenant aussi important et discutable que le résultat final publié.












La modélisation comme processus abductif renvoie en alternance aux données et aux modèle de données, qui elle même renvoie aux hypothèses et aux implémentations de ces hypothèses, aux indicateurs et à la façon dont on les a construit, etc. A l'image des autres outils, il peut être mobilisé de façon hypothético-déductive, ou de façon 



\Anotecontent{hermann_hypothesis}{Le \textit{hypothesis-testing} proposé par Hermann propose d'évaluer avec ce critère la capacité du système simulé à reproduire dans sa dynamique des interactions constatés dans le système observé}

A ce titre la construction des indicateurs que l'on juge capable de caractériser correctement un système observé s'appuie sur une base de connaissance elle même résultat d'un construit. Ainsi, considérer comme pertinente la comparaison terme à terme d'une chaîne d'interaction entre système observés et système simulés \Anote{hermann_hypothesis} revient implicitement à accepter comme satisfaisante une longue et inévitable chaîne d'erreur cumulée, elle même issue d'un long processus de construction (les bases de données en science humaines ne se construisent pas en un jour) qui biaise tout autant la qualité des données initiales (construction d'enquête, de relevés, d'observations), que les structures qui les encadrent (un modèle de répartition par classe d'age par exemple). C'est pourtant sur cette base que le modélisateur doit s'appuyer pour extraire, au regard d'une expertise qui intègre un savoir aussi bien quantitatif que qualitatif, des hypothèses sur les composants et les interactions entre composants dont la pertinence de leur présence dans le modèle s'avère elle même discutable vis à vis de la question posé ..



En un sens, s'appuyer sur l'expression de dynamique \enquote{vraisemblables} pour formuler des hypothèses impactant la suite du raisonnement, et les mécanismes suivant à ajouter au modèle, tel que le propose en substance la \textit{face validity}, semble être une erreur pouvant couter beaucoup de temps de redéveloppement à posteriori.






L'abduction de part l'argument naturaliste évolutionniste qu'on lui prête,dépasse le simple cadre de la logique dans lequel de toute façon elle posait déjà problème, et n'intervient donc pas comme un moyen de preuve : \enquote{ On nous propose plutot d’envisager l’ensemble des démarches par lesquelles les chercheurs s’orientent vers les hypothèses qui semblent plausibles, en éliminant celles qui ne peuvent etre considérées comme pertinente. } A ce titre, \enquote{La démarche abductive permet un authentique gain de sens, une progression dans l’élucidation}


Un argument supplémentaire pour parler d'évaluation plutôt que de validation \autocite{Amblard2006}, car celle-ci s'inscrit dans un projet parallèle à l'activité de construction du modèle, dont la mise en œuvre implique sinon la construction au moins l'existence préalable d'hypothèses, et d'indicateurs pertinents sur le système observé; une expertise cumulé qui dépasse de loin en durée et en travail le seul projet de construction d'un modèle, et fait souvent intervenir un système de modèle dans une démarche de construction des connaissances de portée beaucoup plus large que cette seule construction de modèles de simulation. Un point que l'on a déjà abordé dans le paragraphe \ref{decorreler_validation} pour justifier d'une décorrélation des problématiques de la Validation vue sous l'angle réducteur de cette seule activité de modélisation multi-agents.


Que cela soit les paramètres, valeur de paramètres, hypothèses mobilisés, choix d'implémentation des hypothèses, critères d'évaluations ( fait stylisés ou données ) construit ou choisi, tout ces étapes ne peuvent être mis en oeuvre si on n'accepte pas de voir l'activité de modélisation pour la simulation comme parti prenante d'une activité de construction des connaissances plus globales. C'est ce qui rend aussi difficile l'évaluation de publication soutenant l'originalité d'un modèle de simulation par un public n'ayant pas connaissance de ce système de modèles et des interactions complexes et réflexives qui relient ceux ci, que cela soit en amont ou en parallèle de la construction des modèles de simulations.

Cette démarche globale a été plusieurs fois théorisé par les géographes \autocites{Besse2000, Sanders2000, Mathian2014}, et une application plus explicite des relations que peut entretenir un modèle de simulation avec d'autres type de modélisation (statistique, spatiales) peut être vu dans la thèse de Clémentine Cottineau \autocite{Cottineau2014a, Cottineau2014b}. 

De plus, il reste difficile donc d'éliminer une hypothèse présente dans le modèle en fonction de sa seule mise en défaut observés à un instant $t$ donné dans la construction d'un modèle, notamment lorsque la présence de celle ci fait sens du point de vue des objectifs qui ont été fixés par le modélisateur. 

D'autant plus qu'il faut aussi prendre en compte cette double dynamique dans lequel opère la construction et la complexification des modèles et des indicateurs pour en rendre compte. Une hypothèse valable à un instant $t$ ne le sera peut etre plus à un instant $t + 1$, ou inversement. 

Peut être n'était-ce simplement pas le moment pour intégrer cette hypothèse au modèle, celui-ci étant encore trop simple ? Peut être manquait-il des interactions pour que sa dynamique soit révélé ? Peut être que l'indicateur devant rendre compte de cette dynamique n'est pas adapté ? Peut être que l'implémentation proposé n'était tout simplement pas la plus adapté à ce moment là ? etc. 

Ce qui a mon sens soulève ici plusieurs remarques : 
- il est vraiment difficile de savoir ce qui va se passer avec l'intégration ou le retrait des hypothèses, ou des critères d'évaluation dans un modèle de simulation si on ne dispose pas d'un outil permettant d'évaluer systématiquement chacune de ces modifications, ce point est valable tout autant pour les approche KIDS que KISS.
- cette évaluation doit être mis en place de façon immédiate, dès que les premières questions sont posés à la structure causale du modèle, afin de ne pas biaisé le raisonnement construit par la prolongation d'une phase de \textit{face validity} pouvant très vite devenir problématique de part les redéveloppements qu'elle suppose dans le futur.
- malgré cela, il faut bien voire qu'une exploration des comportements du modèle, même complète, ne fera pas disparaitre ce problème, qui tient avant tout de l'avancement du raisonnement dans la construction du modèle.

Il reste donc à gérer cette possibilité de réengager les hypothèses et les critères à différents moments dans la construction des modèles, et soutenir une activité de construction cumulative qui ne soit pas \enquote{oublieuse} de cette autre espace temps dans lequel se construise les hypothèses et les différents critères mobilisés. 




Une des possibilités pour sortir de cette problématique est je pense double : 
- proposer un historique du raisonnement
- supporter l'équifinalité de façon explicite